{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdb80d3-737a-4306-8c46-3408f98851db",
   "metadata": {},
   "source": [
    "# Quick introduction to the dataloading module\n",
    "\n",
    "This section is intended to provide a brief introduction to the dataloading module and its main functionalities.\n",
    "\n",
    "In short, all functions and custom classes are designed to help you creating an efficient Pytorch Dataloader to use during training. The main objective is to avoid loading the entire dataset locally  A typical pipeline is based on the following steps:\n",
    "\n",
    "1) Call of the **GetEEGPartitionNumber** function to extract the dataset length, i.e. the number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f8ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.getcwd().split('/Notebooks')[0])\n",
    "from selfeeg import dataloading as dl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4ca58",
   "metadata": {},
   "source": [
    "# Operative augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7edbd",
   "metadata": {},
   "source": [
    "## Shifts and Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39489028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_vertical(x: \"N-D Tensor of numpy Array\", \n",
    "                   value: float):\n",
    "    \"\"\"\n",
    "    shift_vertical add a scalar value to the input array x.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D Tensor or numpy array\n",
    "    value: scalar\n",
    "        The value to add\n",
    "    \"\"\"\n",
    "    x_shift = x + value\n",
    "    return x_shift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_vertical(x: \"N-D Tensor of numpy Array\"):\n",
    "    \"\"\"\n",
    "    flip_vertical change the sign of all the elements of the input array x.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    x: N-D Tensor or numpy array\n",
    "    \"\"\"\n",
    "    x_flip= x*(-1)\n",
    "    return x_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542507f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_horizontal(x: \"N-D Tensor of numpy Array\"):\n",
    "    \"\"\"\n",
    "    flip_horizontal flip the elements of the last dimension of x.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    x: N-D Tensor or numpy array\n",
    "        Array to flip. Last dimension must have the EEG recordings\n",
    "    \"\"\"\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x_flip = np.flip(x, len(x.shape)-1)\n",
    "    else:\n",
    "        x_flip = torch.flip(x, [len(x.shape)-1])\n",
    "    \n",
    "    return x_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26e357",
   "metadata": {},
   "source": [
    "## Noise adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe92ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x: \"N-D Tensor of numpy Array\", \n",
    "              mean: float=0., \n",
    "              std: float=1.,\n",
    "              get_noise: bool=False\n",
    "             ):\n",
    "    \"\"\"\n",
    "    add_noise add gaussian noise with the desired mean and standard deviation.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    x: N-D Tensor or numpy array\n",
    "        array to add noise\n",
    "    mean: scalar, optional\n",
    "        the mean of the gaussian distribution\n",
    "        Default: 0\n",
    "    std: scalar, optional\n",
    "        the std of the gaussian distribution\n",
    "        Default: 1\n",
    "    get_noise: bool, optional\n",
    "        whether to return the generated noise or not\n",
    "        Default: False\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(x,np.ndarray):\n",
    "        noise = mean + std * np.random.randn(*x.shape)\n",
    "    else:\n",
    "        noise   = mean +  std * torch.randn(*x.shape, device=x.device)\n",
    "    x_noise = x + noise \n",
    "    if get_noise:\n",
    "        return x_noise, noise\n",
    "    else:\n",
    "        return x_noise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_SNR(x: \"N-D Tensor of numpy Array\", \n",
    "                  target_snr: float=5, \n",
    "                  get_noise: bool=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    add_noise_SNR add noise such that the SNR (Signal to Noise Ratio) will be the one desired.\n",
    "    \n",
    "    Since the signal is supposed to be already noisy, it makes more sense to say that this function reduce \n",
    "    the SNR by a factor equal to 1/P_noise_new, where P_noise_new is the power of the new added noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D Tensor or numpy array\n",
    "        array to add noise\n",
    "    target_SNR: scalar, optional\n",
    "        the target SNR\n",
    "        Default: 5\n",
    "    get_noise: bool, optional\n",
    "        whether to return the generated noise or not\n",
    "        Default: False\n",
    "        \n",
    "    \n",
    "    created using the following reference: \n",
    "        https://stackoverflow.com/questions/14058340/adding-noise-to-a-signal-in-python\n",
    "    \"\"\"\n",
    "    \n",
    "    # get signal power. Not exactly true since we have an already noised signal\n",
    "    x_pow = (x ** 2)\n",
    "    \n",
    "    if isinstance(x,np.ndarray):\n",
    "        x_db = 10 * np.log10(x_pow)\n",
    "        x_pow_avg = np.mean(x_pow)\n",
    "        x_db_avg = 10 * np.log10(x_pow_avg) \n",
    "        noise_db_avg = x_db_avg - target_snr\n",
    "        noise_pow_avg = 10 ** (noise_db_avg / 10)\n",
    "        noise = np.random.normal(0, noise_pow_avg**0.5 , size=x.shape) \n",
    "        x_noise = x + noise\n",
    "    \n",
    "    else:\n",
    "        x_db = 10 * torch.log10(x_pow)\n",
    "        x_pow_avg = torch.mean(x_pow)\n",
    "        x_db_avg = 10 * torch.log10(x_pow_avg)\n",
    "        noise_db_avg = x_db_avg - target_snr\n",
    "        noise_pow_avg = 10 ** (noise_db_avg / 10)\n",
    "        noise = ((noise_pow_avg**0.5)*torch.randn(*x.shape))#.to(device=x.device) \n",
    "        x_noise = x + noise        \n",
    "    \n",
    "    if get_noise:\n",
    "        return x_noise, noise\n",
    "    else:\n",
    "        return x_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_band_noise(x: \"numpy array or tensor\",\n",
    "                   bandwidth: list[tuple[float,float], str, float], \n",
    "                   samplerate: float=256, \n",
    "                   std: float=0.5,\n",
    "                   get_noise: bool=False\n",
    "                  ):\n",
    "    \n",
    "    \"\"\"\n",
    "    add_band noise add random noise filtered at specific bandwidths.\n",
    "    \n",
    "    Given a set of bandwidths or specific a set of specific frequency, add_band_noise create a noise whose \n",
    "    spectrum is bigger than zero only on those bands. It can be used to alter only specific frequency components\n",
    "    of the original signal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D Tensor or numpy array\n",
    "        array to add noise\n",
    "    bandwidth: list\n",
    "        The frequency components which the noise must have. Must be a LIST with the following values:\n",
    "        strings: add noise to specific EEG components. Can be any of \"delta\", \"theta\", \"alpha\", \"beta\", \n",
    "                 \"gamma\", \"gamma_low\", \"gamma_high\"\n",
    "        scalar: add noise to a specifi component\n",
    "        tuple with 2 scalar: add noise to a specific band set with the tuple (start_component, end_component)\n",
    "    samplerate : float, optional\n",
    "        The sampling rate, given in Hz. Remember to change this value according to the signal sampling rate\n",
    "        Default: 256\n",
    "    std: float, optional\n",
    "        The desired standard deviation of the noise. Use to change the magnitude of the noise\n",
    "        Default: 0.5\n",
    "    get_noise: bool, optional\n",
    "        whether to return the generated noise or not\n",
    "        Default: False\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # converting to list if single string or integer is given\n",
    "    if not(isinstance(bandwidth, list)):\n",
    "        bandwidth=[bandwidth]\n",
    "    \n",
    "    # transform all elements in 2 floats tuple\n",
    "    for i in range(len(bandwidth)):\n",
    "        # change string bandwidth call to frequency slice\n",
    "        if isinstance(bandwidth[i],str):\n",
    "            if bandwidth[i].lower() == 'delta':\n",
    "                bandwidth[i]=(0.5,4)\n",
    "            elif bandwidth[i].lower() == 'theta':\n",
    "                bandwidth[i]=(4,8)\n",
    "            elif bandwidth[i].lower() == 'alpha':\n",
    "                bandwidth[i]=(8,13)\n",
    "            elif bandwidth[i].lower() == 'beta':\n",
    "                bandwidth[i]=(13,30)\n",
    "            elif bandwidth[i].lower() == 'gamma_low':\n",
    "                bandwidth[i]=(30,70)\n",
    "            elif bandwidth[i].lower() == 'gamma_high':\n",
    "                bandwidth[i]=(70,150)\n",
    "            elif bandwidth[i].lower() == 'gamma':\n",
    "                bandwidth[i]=(30,150)\n",
    "            else:\n",
    "                message  = 'Brainwave \\\"',bandwidth[i], '\\\" not exist. \\n'\n",
    "                message += 'Choose between delta, theta, alpha, beta, gamma, gamma_low, gamma_high'\n",
    "                raise ValueError(message)\n",
    "        \n",
    "        # change single frequency call\n",
    "        elif np.isscalar(bandwidth[i]):                \n",
    "            bandwidth[i]=(bandwidth[i],bandwidth[i])\n",
    "\n",
    "    N=len(bandwidth)          \n",
    "    samples = x.shape[-1]\n",
    "    if isinstance(x,np.ndarray):\n",
    "        \n",
    "        f = np.zeros(samples, dtype='complex')\n",
    "        for i in range(N):\n",
    "            start = int(bandwidth[i][0]*samples/samplerate)\n",
    "            end = int(bandwidth[i][1]*samples/samplerate +1)\n",
    "            f[start:end] = 1\n",
    "        Np = (len(f) - 1) // 2\n",
    "        phases = np.random.rand(Np) * 2 * np.pi\n",
    "        phases = np.cos(phases) + 1j * np.sin(phases)\n",
    "        f[1:Np+1] *= phases\n",
    "        f[-1:-1-Np:-1] = np.conj(f[1:Np+1])\n",
    "        noise = np.fft.ifft(f).real   \n",
    "        G = std/np.std(noise)\n",
    "        noise *= G\n",
    "        x_noise= x+noise\n",
    "               \n",
    "    else:\n",
    "        f = torch.zeros(samples, dtype=torch.complex64, device=x.device)\n",
    "        for i in range(N):\n",
    "            start = int(bandwidth[i][0]*samples/samplerate)\n",
    "            end = int(bandwidth[i][1]*samples/samplerate +1)\n",
    "            f[start:end] = 1\n",
    "        Np = (samples - 1) // 2\n",
    "        phases = torch.rand(Np, device=x.device)\n",
    "        phases =  phases * 2 * math.pi\n",
    "        phases = torch.cos(phases) + 1j * torch.sin(phases)\n",
    "        f[1:Np+1] *= phases\n",
    "        f[-Np:] = torch.flip(torch.conj(f[1:Np+1]), [0])\n",
    "        noise = torch.fft.ifft(f).real   \n",
    "        G = std/torch.std(noise)\n",
    "        noise *= G\n",
    "        x_noise= x+noise\n",
    "\n",
    "    \n",
    "    if get_noise:\n",
    "        return x_noise , noise\n",
    "    else:\n",
    "        return x_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57547ad",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f58518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg(x, order: int=5, pad_mode: str='same'):\n",
    "    \"\"\"\n",
    "    moving_avg apply a moving average filter to the signal x.\n",
    "    \n",
    "    moving_avg apply a moving average filter to the last dimension of the array or Tensor x. The filter order\n",
    "    and padding strategy can be given as function argument.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D Tensor or numpy array\n",
    "        The element to filter. Signals must be on the last dimension.\n",
    "    order: int, optional\n",
    "        The order of the filter.\n",
    "        Default: 5\n",
    "    pad_mode: str or int or tuple of int\n",
    "        The padding strategy. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    if isinstance(x, np.ndarray):\n",
    "        x_avg = np.empty_like(x)\n",
    "        filt = np.ones(order)/order\n",
    "        Ndim= len(x.shape)\n",
    "        \n",
    "        # call recursively to handle different dimensions (made to handle problem with torch conv2d)\n",
    "        if Ndim>1:\n",
    "            for i in range(x.shape[0]):\n",
    "                x_avg[i] = moving_avg(x[i], order=order, pad_mode=pad_mode)\n",
    "        else:\n",
    "            x_avg = np.convolve( x, filt, pad_mode)\n",
    "            \n",
    "    else:\n",
    "        Ndim = len(x.shape)\n",
    "        # adapt to x to conv2d functions\n",
    "        if Ndim==1:\n",
    "            x = x.view(1,1,1,*x.shape)\n",
    "        elif Ndim==2:\n",
    "            x = x.view(1,1, *x.shape)\n",
    "        elif Ndim==3:\n",
    "            x = x.unsqueeze(1)\n",
    "        x_avg = torch.empty_like(x)\n",
    "        filt = torch.ones((1,1,1,order), device=x.device)/order\n",
    "        \n",
    "        # call recursively if the dimension is larger than 4\n",
    "        if Ndim > 4:\n",
    "            for i in range(x.shape[0]):\n",
    "                x_avg[i] = moving_avg(x[i], order=order, pad_mode=pad_mode)\n",
    "        else:\n",
    "            x_avg = F.conv2d(x, filt, padding= pad_mode)\n",
    "            x_avg = torch.reshape(x_avg, x.shape)\n",
    "\n",
    "    \n",
    "    return x_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914261e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_coeff(Wp: float, \n",
    "                     Ws: float,\n",
    "                     rp: float=-20*np.log10(.95), \n",
    "                     rs: float=-20*np.log10(.15), \n",
    "                     btype: str='low', \n",
    "                     filter_type: str='butter', \n",
    "                     order: int=None, \n",
    "                     Wn: Union[float,List[float]]=None, \n",
    "                     eeg_band: str=None, \n",
    "                     Fs: float=None\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    get_filter_coeff returns the filter coefficients a and b needed to call the scipy's or torchaudio's \n",
    "    filtfilt function.\n",
    "    \n",
    "    get_filter_coeff is internally called by other filtering function when a and b coefficients are not given\n",
    "    as input argument. It works following this priority pipeline:\n",
    "    1) if specific EEG bands are given, set Wp, Ws, rp, rs for filter design according to the given band\n",
    "    2) if order and Wn are not given, use previous parameter to design the filter\n",
    "    3) Use Wn and order to get a and b coefficient to return\n",
    "    \n",
    "    In other words (Wp,Ws,rp,rs) ----> (Wn, order) -----> (a,b) \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Wp: float\n",
    "        bandpass normalized from 0 to 1\n",
    "    Ws: float\n",
    "        stopband normalized from 0 to 1\n",
    "    rp: float, optional\n",
    "        ripple at bandpass in decibel. \n",
    "        Default: -20*log10(0.95)\n",
    "    rs: float, optional\n",
    "        ripple at stopband in decibel. \n",
    "        Default: -20*log10(0.15)\n",
    "    btype: str, optional\n",
    "        filter type. Can be any of the scipy's btype argument (e.g. 'lowpass', 'highpass', 'bandpass')\n",
    "        Default: 'low'\n",
    "    filter_type: str, optional\n",
    "        which filter design. Accepted values are 'butter', 'ellip', 'cheby1', 'cheby2'\n",
    "        Default: 'butter'\n",
    "    order: int, optional\n",
    "        the order of the filter\n",
    "        Default: None\n",
    "    Wn: array_like, optional\n",
    "        the critical frequency or frequencies.\n",
    "        Default: None\n",
    "    eeg_band: str, optional\n",
    "        any of the possible EEG bands. Accepted values are \"delta\", \"theta\", \"alpha\", \"beta\", \n",
    "        \"gamma\", \"gamma_low\", \"gamma_high\".\n",
    "        Default: None\n",
    "    Fs: float, optional\n",
    "        the sampling frequency. Must be given if eeg_band is also given\n",
    "        Default: None\n",
    "    \"\"\"\n",
    "    \n",
    "    if btype.lower() == 'bandpass':\n",
    "        if eeg_band is not None:\n",
    "            if eeg_band.lower() == 'delta':\n",
    "                Wp, Ws, rp, rs, btype = 4, 8, -20*np.log10(.95), -20*np.log10(.1), 'lowpass'\n",
    "            elif eeg_band.lower() == 'theta':\n",
    "                Wp, Ws, rp, rs = [4, 8], [0, 15], -20*np.log10(.95), -20*np.log10(.1)\n",
    "            elif eeg_band.lower() == 'alpha':\n",
    "                Wp, Ws, rp, rs = [8, 13], [4, 22], -20*np.log10(.95), -20*np.log10(.1)\n",
    "            elif eeg_band.lower() == 'beta':\n",
    "                Wp, Ws, rp, rs = [13, 30], [8, 40], -20*np.log10(.95), -20*np.log10(.15)\n",
    "            elif eeg_band.lower() == 'gamma_low':\n",
    "                Wp, Ws, rp, rs = [30, 70], [22, 78], -20*np.log10(.95), -20*np.log10(.1)\n",
    "            elif eeg_band.lower() == 'gamma_high':\n",
    "                if Fs>=158*2:\n",
    "                    Wp, Ws, rp, rs = [70, 150], [62, 158], -20*np.log10(.95), -20*np.log10(.1)\n",
    "                else:\n",
    "                    Wp, Ws, rp, rs, btype = 70, 62, -20*np.log10(.95), -20*np.log10(.1), 'highpass'\n",
    "            elif eeg_band.lower() == 'gamma':\n",
    "                if Fs>=158*2:\n",
    "                    Wp, Ws, rp, rs = [30, 150], [22, 158], -20*np.log10(.95), -20*np.log10(.1)\n",
    "                else:\n",
    "                    Wp, Ws, rp, rs, btype = 30, 22, -20*np.log10(.95), -20*np.log10(.1), 'highpass'\n",
    "            else:\n",
    "                message  = 'Brainwave \\\"',bandwidth[i], '\\\" not exist. \\n'\n",
    "                message += 'Choose between delta, theta, alpha, beta, gamma, gamma_low, gamma_high'\n",
    "                raise ValueError(message)\n",
    "            Wp, Ws = np.array(Wp)/(Fs/2), np.array(Ws)/(Fs/2)\n",
    "    \n",
    "    if (order is None) or (Wn is None):\n",
    "        if filter_type.lower()=='butter':\n",
    "            order, Wn = signal.buttord(Wp, Ws, rp, rs)\n",
    "        elif filter_type.lower()=='ellip':\n",
    "            order, Wn = signal.ellipord(Wp, Ws, rp, rs)\n",
    "        elif filter_type.lower()=='cheby1':\n",
    "            order, Wn = signal.cheb1ord(Wp, Ws, rp, rs)\n",
    "        elif filter_type.lower()=='cheby2':\n",
    "            order, Wn = signal.cheb2ord(Wp, Ws, rp, rs)\n",
    "    \n",
    "    if filter_type.lower()=='butter':\n",
    "        b, a = signal.butter(order, Wn, btype)\n",
    "    elif filter_type.lower()=='ellip':\n",
    "        b, a = signal.ellip(order, rp, rs, Wn, btype)\n",
    "    elif filter_type.lower()=='cheby1':\n",
    "        b, a = signal.cheby1(order,rp, Wn, btype)\n",
    "    elif filter_type.lower()=='cheby2':\n",
    "        b, a = signal.cheby2(order, rs, Wn, btype)\n",
    "    \n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19983cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lowpass(x: \"array or tensor\", \n",
    "                   Wp: float=50,\n",
    "                   Ws: float=70,\n",
    "                   rp: float=-20*np.log10(.95), \n",
    "                   rs: float=-20*np.log10(.15),\n",
    "                   filter_type: str='butter',\n",
    "                   order: int=None, \n",
    "                   Wn: float=None,\n",
    "                   a: Union[np.ndarray,float]=None,\n",
    "                   b: Union[np.ndarray,float]=None,\n",
    "                   return_filter_coeff: bool=False\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    filter_lowpass apply a lowpass filter on the last dimension of the given input x.\n",
    "    \n",
    "    filter_lowpass apply a designed lowpass filter on the last dimension of x. If a and b coefficient are not \n",
    "    given, calls get_filter_coeff with the other arguments to get them. The filter dedign follow this order:\n",
    "                            (Wp,Ws,rp,rs) ----> (Wn, order) -----> (a,b). \n",
    "    Therefore the arguments closer to a and b in the scheme are used to get the filter coefficient.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D array or Tensor\n",
    "        The element to filter\n",
    "    Wp: float, optional\n",
    "        bandpass in Hz\n",
    "        Default: 50\n",
    "    Ws: float, optional\n",
    "        stopband in Hz\n",
    "        Default: 70\n",
    "    rp: float, optional\n",
    "        ripple at bandpass in decibel. \n",
    "        Default: -20*log10(0.95)\n",
    "    rs: float, optional\n",
    "        ripple at stopband in decibel. \n",
    "        Default: -20*log10(0.15)\n",
    "    filter_type: str, optional\n",
    "        which filter design. Accepted values are 'butter', 'ellip', 'cheby1', 'cheby2'\n",
    "        Default: 'butter'\n",
    "    order: int, optional\n",
    "        the order of the filter\n",
    "        Default: None\n",
    "    Wn: array_like, optional\n",
    "        the critical frequency or frequencies.\n",
    "        Default: None\n",
    "    a: array_like, optional\n",
    "        the denominator coefficient of the filter\n",
    "        Default: None\n",
    "    b: array_like, optional\n",
    "        the numerator coefficient of the filer\n",
    "        Default: None\n",
    "    return_filter_coeff: bool, optional\n",
    "        whether to return the filter coefficient or not\n",
    "        Default: False\n",
    "        \n",
    "    NOTE: pytorch filtfilt works differently on edges and is pretty unstable with high order filters, so avoid \n",
    "    restrictive condition which can increase the order of the filter.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if filter_type not in ['butter', 'ellip', 'cheby1', 'cheby2']:\n",
    "        raise ValueError('filter type not supported. Choose between butter, elliptic, cheby1, cheby2')\n",
    "    \n",
    "    if (a is None) or (b is None):\n",
    "        b, a = get_filter_coeff(Wp = Wp, Ws = Ws, rp = rp, rs = rs, btype = 'lowpass', \n",
    "                                filter_type = filter_type, order = order, Wn = Wn,eeg_band = None, Fs = None \n",
    "                               )\n",
    "         \n",
    "    if isinstance(x, np.ndarray):\n",
    "        x_filt = signal.filtfilt(b, a, x, padtype='constant' )  \n",
    "    else:\n",
    "        a= torch.from_numpy(a).to(dtype=x.dtype, device=x.device)\n",
    "        b= torch.from_numpy(b).to(dtype=x.dtype, device=x.device)\n",
    "        x_filt = filtfilt(x, a, b, clamp=False)   \n",
    "    \n",
    "    if return_filter_coeff:\n",
    "        return x_filt, b, a\n",
    "    else:\n",
    "        return x_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a005d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_highpass(x: \"array or tensor\", \n",
    "                    Wp: float=30,\n",
    "                    Ws: float=13,\n",
    "                    rp: float=-20*np.log10(.95), \n",
    "                    rs: float=-20*np.log10(.15),\n",
    "                    filter_type: str='butter',\n",
    "                    order: int=None, \n",
    "                    Wn: float=None,\n",
    "                    a: Union[np.ndarray,float]=None,\n",
    "                    b: Union[np.ndarray,float]=None,\n",
    "                    return_filter_coeff: bool=False\n",
    "                   ):\n",
    "    \n",
    "    \"\"\"\n",
    "    filter_highpass apply a highpass filter on the last dimension of the given input x.\n",
    "    \n",
    "    filter_highpass apply a designed highpass filter on the last dimension of x. If a and b coefficient are not \n",
    "    given, calls get_filter_coeff with the other arguments to get them. The filter dedign follow this order:\n",
    "                            (Wp,Ws,rp,rs) ----> (Wn, order) -----> (a,b). \n",
    "    Therefore the arguments closer to a and b in the scheme are used to get the filter coefficient.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D array or Tensor\n",
    "        The element to filter\n",
    "    Wp: float, optional\n",
    "        bandpass in Hz\n",
    "        Default: 30\n",
    "    Ws: float, optional\n",
    "        stopband in Hz\n",
    "        Default: 13\n",
    "    rp: float, optional\n",
    "        ripple at bandpass in decibel. \n",
    "        Default: -20*log10(0.95)\n",
    "    rs: float, optional\n",
    "        ripple at stopband in decibel. \n",
    "        Default: -20*log10(0.15)\n",
    "    filter_type: str, optional\n",
    "        which filter design. Accepted values are 'butter', 'ellip', 'cheby1', 'cheby2'\n",
    "        Default: 'butter'\n",
    "    order: int, optional\n",
    "        the order of the filter\n",
    "        Default: None\n",
    "    Wn: array_like, optional\n",
    "        the critical frequency or frequencies.\n",
    "        Default: None\n",
    "    a: array_like, optional\n",
    "        the denominator coefficient of the filter\n",
    "        Default: None\n",
    "    b: array_like, optional\n",
    "        the numerator coefficient of the filer\n",
    "        Default: None\n",
    "    return_filter_coeff: bool, optional\n",
    "        whether to return the filter coefficient or not\n",
    "        Default: False\n",
    "        \n",
    "    NOTE: pytorch filtfilt works differently on edges and is pretty unstable with high order filters, so avoid \n",
    "    restrictive condition which can increase the order of the filter.\n",
    "    \"\"\"\n",
    "    \n",
    "    if filter_type not in ['butter', 'ellip', 'cheby1', 'cheby2']:\n",
    "        raise ValueError('filter type not supported. Choose between butter, elliptic, cheby1, cheby2')\n",
    "    \n",
    "    if (a is None) or (b is None):\n",
    "        b, a = get_filter_coeff(Wp = Wp, Ws = Ws, rp = rp, rs = rs, btype = 'highpass', \n",
    "                                filter_type = filter_type, order = order, Wn = Wn,eeg_band = None, Fs = None \n",
    "                               )\n",
    "         \n",
    "    if isinstance(x, np.ndarray):\n",
    "        x_filt = signal.filtfilt(b, a, x, padtype='constant' )  \n",
    "    else:\n",
    "        a= torch.from_numpy(a).to(dtype=x.dtype, device=x.device)\n",
    "        b= torch.from_numpy(b).to(dtype=x.dtype, device=x.device)\n",
    "        x_filt = filtfilt(x, a, b, clamp=False)   \n",
    "    \n",
    "    if return_filter_coeff:\n",
    "        return x_filt, b, a\n",
    "    else:\n",
    "        return x_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bandpass(x: \"array or tensor\", \n",
    "                    Wp: list[float]=None,\n",
    "                    Ws: list[float]=None,\n",
    "                    rp: float=-20*np.log10(.95), \n",
    "                    rs: float=-20*np.log10(.05),\n",
    "                    filter_type: str='butter',\n",
    "                    order: int=None, \n",
    "                    Wn: float=None,\n",
    "                    a: Union[np.ndarray,float]=None,\n",
    "                    b: Union[np.ndarray,float]=None,\n",
    "                    eeg_band: str=None,\n",
    "                    Fs: float=None,\n",
    "                    return_filter_coeff: bool=False\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    filter_bandpass apply a bandpass filter on the last dimension of the given input x.\n",
    "    \n",
    "    filter_bandpass apply a designed bandpass filter on the last dimension of x. If a and b coefficient are not \n",
    "    given, calls get_filter_coeff with the other arguments to get them. The filter dedign follow this order:\n",
    "                            (Wp,Ws,rp,rs) ----> (Wn, order) -----> (a,b). \n",
    "    Therefore the arguments closer to a and b in the scheme are used to get the filter coefficient.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: N-D array or Tensor\n",
    "        The element to filter\n",
    "    Wp: float, optional\n",
    "        bandpass in Hz.\n",
    "        Default: 30\n",
    "    Ws: float, optional\n",
    "        stopband in Hz\n",
    "        Default: 13\n",
    "    rp: float, optional\n",
    "        ripple at bandpass in decibel. \n",
    "        Default: -20*log10(0.95)\n",
    "    rs: float, optional\n",
    "        ripple at stopband in decibel. \n",
    "        Default: -20*log10(0.15)\n",
    "    filter_type: str, optional\n",
    "        which filter design. Accepted values are 'butter', 'ellip', 'cheby1', 'cheby2'\n",
    "        Default: 'butter'\n",
    "    order: int, optional\n",
    "        the order of the filter\n",
    "        Default: None\n",
    "    Wn: array_like, optional\n",
    "        the critical frequency or frequencies.\n",
    "        Default: None\n",
    "    a: array_like, optional\n",
    "        the denominator coefficient of the filter\n",
    "        Default: None\n",
    "    b: array_like, optional\n",
    "        the numerator coefficient of the filer\n",
    "        Default: None\n",
    "    eeg_band: str, optional\n",
    "        any of the possible EEG bands. Accepted values are \"delta\", \"theta\", \"alpha\", \"beta\", \n",
    "        \"gamma\", \"gamma_low\", \"gamma_high\".\n",
    "        Default: None\n",
    "    Fs: float, optional\n",
    "        the sampling frequency. Must be given if eeg_band is also given\n",
    "        Default: None\n",
    "    return_filter_coeff: bool, optional\n",
    "        whether to return the filter coefficient or not\n",
    "        Default: False\n",
    "        \n",
    "    NOTE: pytorch filtfilt works differently on edges and is pretty unstable with high order filters, so avoid \n",
    "    restrictive condition which can increase the order of the filter.\n",
    "    \"\"\"\n",
    "    \n",
    "    if filter_type not in ['butter', 'ellip', 'cheby1', 'cheby2']:\n",
    "        raise ValueError('filter type not supported. Choose between butter, elliptic, cheby1, cheby2')\n",
    "    \n",
    "    if (a is None) or (b is None):\n",
    "        b, a = get_filter_coeff(Wp = Wp, Ws = Ws, rp = rp, rs = rs, btype = 'bandpass', \n",
    "                                filter_type = filter_type, order = order, Wn = Wn,eeg_band = eeg_band, Fs = Fs \n",
    "                               )\n",
    "         \n",
    "    if isinstance(x, np.ndarray):\n",
    "        x_filt = signal.filtfilt(b, a, x, padtype='constant' )  \n",
    "    else:\n",
    "        a= torch.from_numpy(a).to(dtype=x.dtype, device=x.device)\n",
    "        b= torch.from_numpy(b).to(dtype=x.dtype, device=x.device)\n",
    "        x_filt = filtfilt(x, a, b, clamp=False) \n",
    "    \n",
    "    if return_filter_coeff:\n",
    "        return x_filt, b, a\n",
    "    else:\n",
    "        return x_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7080f9",
   "metadata": {},
   "source": [
    "## Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg_channel_network_names():\n",
    "    \n",
    "    DMN= np.array(['AF4', 'AF7', 'AF8', 'AFZ', 'CP3', 'CP4', 'CP5', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6',\n",
    "                   'F7', 'F8', 'FC1', 'FC3', 'FC4', 'FC5', 'FP1', 'FP2', 'FPZ', 'FT10', 'FT8', 'FT9',\n",
    "                   'FZ', 'P3', 'P4', 'P5', 'T7', 'T8', 'TP7', 'TP8'], dtype='<U4')\n",
    "    DAN= np.array(['C5', 'C6', 'CP1', 'CP2', 'CPZ', 'FC1', 'FC2', 'FC5', 'P1', 'P2',\n",
    "                   'P7', 'P8', 'PO3', 'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4')\n",
    "    VAN= np.array(['AF3', 'AF4', 'AF8', 'C5', 'C6', 'CP1', 'CP2', 'CP4', 'CP5', 'CP6',\n",
    "                   'CPZ', 'F7', 'F8', 'FC1', 'FC2', 'FC5', 'FC6', 'FT7', 'P1', 'P2',\n",
    "                   'P7', 'P8', 'PO3', 'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4')\n",
    "    SMN= np.array(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'CP1', 'CP2', 'CP5', 'CPZ',\n",
    "                   'CZ', 'FC5', 'FC6', 'FCZ', 'FT8', 'FTZ', 'P3', 'P5','P6', 'P7', 'P8',\n",
    "                   'PO4', 'PO7', 'PO8', 'T7', 'T8', 'TP7'], dtype='<U4')\n",
    "    VFN= np.array(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'CP1', 'CP2', 'CPZ', 'FC1',\n",
    "                   'FC5', 'FC6', 'FT8', 'FTZ', 'O1', 'O2', 'OZ', 'P7', 'P8', 'PO3',\n",
    "                   'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4') \n",
    "    FPN= np.array(['AF3', 'AF4', 'AF7', 'AF8', 'AFZ', 'C6', 'CP3', 'CP4', 'CP5',\n",
    "                   'CP6', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'FC1',\n",
    "                   'FC2', 'FC3', 'FC4', 'FC5', 'FC6', 'FP1', 'FP2', 'FPZ', 'FT10',\n",
    "                   'FT7', 'FT9', 'FZ', 'P3', 'P4', 'P5', 'T7', 'T8', 'TP7', 'TP8'], dtype='<U4')\n",
    "    print('Default Mode Network - DMN')\n",
    "    print(DMN)\n",
    "    print('')\n",
    "    print('Dorsal Attention Network - DAN')\n",
    "    print(DAN)\n",
    "    print('')\n",
    "    print('Ventral Attention Network - VAN')\n",
    "    print(VAN)\n",
    "    print('')\n",
    "    print('SomatoMotor functional Network - SMN')\n",
    "    print(SMN)\n",
    "    print('')\n",
    "    print('Visual Functional Network - VFN')\n",
    "    print(VFN)\n",
    "    print('')\n",
    "    print('FrontoParietal Network - FPN')\n",
    "    print(FPN)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_map_and_networks(channel_map: list=None,\n",
    "                                 chan_net: list[str]='all',\n",
    "                                ):\n",
    "    \"\"\"\n",
    "    get_channel_map_and_networks simply return the channel_map and chan_net argument for permute_channels.\n",
    "    Run help(permute_channels) to get more informations.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if channel_map is None:\n",
    "        channel_map = np.array(['FP1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5',\n",
    "                                'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3',\n",
    "                                'CP1', 'P1', 'P3', 'P5', 'P7', 'PO7', 'PO3', 'O1', 'OZ',\n",
    "                                'POZ', 'PZ', 'CPZ', 'FPZ', 'FP2', 'AF8', 'AF4', 'AFZ', 'FZ',\n",
    "                                'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCZ',\n",
    "                                'CZ', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2',\n",
    "                                'P2', 'P4', 'P6', 'P8', 'PO8', 'PO4', 'O2'], dtype='<U4')\n",
    "    elif isinstance(channel_map, list):\n",
    "        channel_map = np.array(channel_map, dtype='<U4')\n",
    "    \n",
    "    # define networks (according to rojas et al. 2018)\n",
    "    DMN= np.array(['AF4', 'AF7', 'AF8', 'AFZ', 'CP3', 'CP4', 'CP5', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6',\n",
    "                   'F7', 'F8', 'FC1', 'FC3', 'FC4', 'FC5', 'FP1', 'FP2', 'FPZ', 'FT10', 'FT8', 'FT9',\n",
    "                   'FZ', 'P3', 'P4', 'P5', 'T7', 'T8', 'TP7', 'TP8'], dtype='<U4')\n",
    "    DAN= np.array(['C5', 'C6', 'CP1', 'CP2', 'CPZ', 'FC1', 'FC2', 'FC5', 'P1', 'P2',\n",
    "                   'P7', 'P8', 'PO3', 'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4')\n",
    "    VAN= np.array(['AF3', 'AF4', 'AF8', 'C5', 'C6', 'CP1', 'CP2', 'CP4', 'CP5', 'CP6',\n",
    "                   'CPZ', 'F7', 'F8', 'FC1', 'FC2', 'FC5', 'FC6', 'FT7', 'P1', 'P2',\n",
    "                   'P7', 'P8', 'PO3', 'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4')\n",
    "    SMN= np.array(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'CP1', 'CP2', 'CP5', 'CPZ',\n",
    "                   'CZ', 'FC5', 'FC6', 'FCZ', 'FT8', 'FTZ', 'P3', 'P5','P6', 'P7', 'P8',\n",
    "                   'PO4', 'PO7', 'PO8', 'T7', 'T8', 'TP7'], dtype='<U4')\n",
    "    VFN= np.array(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'CP1', 'CP2', 'CPZ', 'FC1',\n",
    "                   'FC5', 'FC6', 'FT8', 'FTZ', 'O1', 'O2', 'OZ', 'P7', 'P8', 'PO3',\n",
    "                   'PO4', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'TP8'], dtype='<U4') \n",
    "    FPN= np.array(['AF3', 'AF4', 'AF7', 'AF8', 'AFZ', 'C6', 'CP3', 'CP4', 'CP5',\n",
    "                   'CP6', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'FC1',\n",
    "                   'FC2', 'FC3', 'FC4', 'FC5', 'FC6', 'FP1', 'FP2', 'FPZ', 'FT10',\n",
    "                   'FT7', 'FT9', 'FZ', 'P3', 'P4', 'P5', 'T7', 'T8', 'TP7', 'TP8'], dtype='<U4')\n",
    "    networks =[DMN, DAN, VAN, SMN, VFN, FPN]\n",
    "\n",
    "    if isinstance(chan_net, str):\n",
    "        chan_net = [chan_net]\n",
    "\n",
    "    net_idx=[]\n",
    "    for i in range(len(chan_net)):\n",
    "        if chan_net[i].lower() == 'all':\n",
    "            net_idx = [0,1,2,3,4,5]\n",
    "            break\n",
    "        elif chan_net[i].lower() == 'dmn':\n",
    "            net_idx.append(0)\n",
    "        elif chan_net[i].lower() == 'dan':\n",
    "            net_idx.append(1)\n",
    "        elif chan_net[i].lower() == 'van':\n",
    "            net_idx.append(2)\n",
    "        elif chan_net[i].lower() == 'smn':\n",
    "            net_idx.append(3) \n",
    "        elif chan_net[i].lower() == 'vfn':\n",
    "            net_idx.append(4)\n",
    "        elif chan_net[i].lower() == 'fpn':\n",
    "            net_idx.append(5)\n",
    "        else:\n",
    "            raise ValueError('brain network not supported. Can be any of DMN, DAN, VAN, SMN, VFN, FPN')\n",
    "\n",
    "    for index in sorted( set([0,1,2,3,4,5])-set(net_idx) , reverse=True):\n",
    "        networks.pop(index)\n",
    "    random.shuffle(networks)\n",
    "    \n",
    "    return channel_map, networks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_channels(x, \n",
    "                     chan2shuf: int=-1,\n",
    "                     mode: str=\"random\",\n",
    "                     channel_map: list=None,\n",
    "                     chan_net: list[str]='all',\n",
    "                     batch_equal: bool=False\n",
    "                    ):\n",
    "    \n",
    "    \"\"\"\n",
    "    permutation_channels permute the input tensor EEG signals x along the channel dimension (second to last).\n",
    "    \n",
    "    Given an input x where the last two dimension must be (EEG_channels x EEG_samples), permutation_channels \n",
    "    shuffles all or a subset of the eeg along its channels. Shuffles can be done randomly or using specific\n",
    "    networks (based on resting state functional connectivity networks).\n",
    "    If batch_equal is set to False, call the function recursively along each of the (N_{1}*N_{2}...*N{-3}) \n",
    "    dimensions of the tensor.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    x: N-D Tensor or numpy array\n",
    "        The element to shuffle. The last two dimensions must be (EEG_channel x EEG_samples), which means that the \n",
    "        permutation is applied on the second to last dimension. \n",
    "    chan2shuf: int, optional\n",
    "        The number of channels to shuffle. Must be greater than 1. -1 is the only accepted negative number and \n",
    "        means permute all the segments.\n",
    "        Default: -1\n",
    "    mode: str, optional\n",
    "        How to permute the channels. Can be any of:\n",
    "            'random': shuffle channels at random\n",
    "            'network': shuffle channels which belongs to the same network. A network is a subset of channels whose\n",
    "                       activity is (with a minumum degree) between each other. This mode support only a subset of\n",
    "                       61 channels of the 10-10 system\n",
    "        Default: 'random'\n",
    "    channel_map: list of str, optional\n",
    "        The channel map of EEG acquisitions. Must be a list of string or a numpy array of dtype='<U4' with channel \n",
    "        names as elements. Channel name must be defined with capital letters (e.g. 'P04', 'FC5').\n",
    "        Default: np.array(['FP1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', \n",
    "                            'C5', 'T7', 'TP7', 'CP5', 'CP3','CP1', 'P1', 'P3', 'P5', 'P7', 'PO7', 'PO3', 'O1', \n",
    "                            'OZ', 'POZ', 'PZ', 'CPZ', 'FPZ', 'FP2', 'AF8', 'AF4', 'AFZ', 'FZ', 'F2', 'F4', 'F6', \n",
    "                            'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCZ', 'CZ', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', \n",
    "                            'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'PO8', 'PO4'],dtype='<U4')\n",
    "    chan_net: str or list of str, optional\n",
    "        The list of networks to use if network mode is selected. Must be a list of string or a single string.\n",
    "        Supported networks are DMN, DAN, VAN, SMN, VFN, FPN. Use 'all' to select all networks. To get a list of\n",
    "        the channel names per network use get_eeg_network_channel_names()\n",
    "        Default: 'all'\n",
    "    batch_equal: bool, optional\n",
    "        whether to apply the same permutation to all EEG record or not. If True, permute_signal is called \n",
    "        recursively for each dimension of the batch until the last two are reached (e.g. given a tensor x\n",
    "        of dimension (16,8,64,512) the function permute each of the 16*8 EEG signals (64 channels of 512 samples)\n",
    "        individually).\n",
    "        Default: False\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Nchan=x.shape[-2]\n",
    "    Ndim= len(x.shape)\n",
    "    \n",
    "    # Check if given input is ok \n",
    "    if (chan2shuf==1) or (chan2shuf==0) or (chan2shuf>Nchan):\n",
    "        msgLog='chan2shuf must be bigger than 1 and smaller than the number of channels in the recorded EEG. \\n '\n",
    "        msgLog += 'Default value is -1, which means all EEG channels are shuffled'\n",
    "        raise ValueError(msgLog)\n",
    "    if Ndim==1:\n",
    "        raise ValueError('x must be an array or tensor with the last two dimensions [channel]*[time window]')\n",
    "    \n",
    "    chan2shuf = x.shape[-2] if chan2shuf==-1 else chan2shuf \n",
    "    x2= np.empty_like(x) if isinstance(x, np.ndarray) else torch.empty_like(x)\n",
    "    if (Ndim<3) or (batch_equal):\n",
    "        \n",
    "        if mode.lower()=='network':\n",
    "            # Define or check channel map and channel networks\n",
    "            channel_map , networks = get_channel_map_and_networks(channel_map, chan_net)\n",
    "            if channel_map.shape[0] != x.shape[-2]:\n",
    "                raise ValueError('channel map does not match the number of channels in eeg recording')\n",
    "\n",
    "            # randomly select a number of channels equals to chan2shuf\n",
    "            idxor_full = np.random.permutation(np.arange(Nchan, dtype=int))[:chan2shuf]\n",
    "            idxor_full = np.sort(idxor_full)\n",
    "            idx_full=np.full(chan2shuf, -1, dtype=int)\n",
    "\n",
    "            # shuffle according to the selected networks\n",
    "            for k in range(len(networks)):\n",
    "                idxor = np.where(np.in1d(channel_map[idxor_full], networks[k]))[0] #identify chans idx\n",
    "                idxor = idxor[np.where(idx_full[idxor]==-1)[0]] # keep only non shuffled channels\n",
    "                idx = (idxor_full[idxor]) #get chans idx\n",
    "                if idx.shape[0]>1:\n",
    "                    while len(np.where(idx==idxor_full[idxor])[0])>0:\n",
    "                        np.random.shuffle(idx)\n",
    "                idx_full[idxor]=idx\n",
    "\n",
    "            # final results\n",
    "            idxor = idxor_full\n",
    "            idx = idx_full   \n",
    "            if not(isinstance(x,np.ndarray)):\n",
    "                idxor = torch.from_numpy(idxor_full).to(device=x.device)\n",
    "                idx = torch.from_numpy(idx_full).to(device=x.device)\n",
    "\n",
    "        \n",
    "        # random mode shuffle channels at random\n",
    "        elif mode.lower()=='random':\n",
    "            if isinstance(x, np.ndarray):\n",
    "                idx = np.arange(Nchan, dtype=int)\n",
    "                np.random.shuffle(idx)\n",
    "                idx = idx[:chan2shuf]\n",
    "                idxor = np.sort(idx)\n",
    "                if len(idx)>1:\n",
    "                    while len(np.where(idx==idxor)[0])>0:\n",
    "                        np.random.shuffle(idx)\n",
    "            else:\n",
    "                idx = torch.randperm(Nchan, device=x.device)\n",
    "                idx = idx[:chan2shuf]\n",
    "                idxor, _ = torch.sort(idx)\n",
    "                if len(idx)>1:\n",
    "                    while torch.sum(torch.eq(idx,idxor))!=0:\n",
    "                        idx = idx[torch.randperm(idx.shape[0], device=x.device)]\n",
    "\n",
    "        # apply defined shuffle\n",
    "        xtemp = x[..., idx, :]\n",
    "        x2[...,idxor,:] = xtemp\n",
    "    \n",
    "    else:\n",
    "        # call recursively for each dimension until last 2 are reached\n",
    "        for i in range(x.shape[0]):\n",
    "            x2[i] = permute_channels(x[i], chan2shuf= chan2shuf, mode=mode, \n",
    "                                     channel_map=channel_map, chan_net=chan_net)\n",
    "               \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace01f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_signal(x, \n",
    "                       segments: int=10, \n",
    "                       seg_to_per: int=-1,\n",
    "                       batch_equal: bool=False\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    permutation_signal permute some portion of the last dimension of the input N-D array_like x\n",
    "    \n",
    "    Given an input x where the last two dimension must be (EEG_channels x EEG_samples), permutation_signal \n",
    "    divides the elements of the last dimension of x into N segments, then chooses M<=N segments and shuffle it. \n",
    "    Permutations are equally performed along each Channel of the same EEG. \n",
    "    If batch_equal is set to False, call the function recursively along each of the (N_{1}*N_{2}...*N{-3}) \n",
    "    dimensions of the tensor.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    x: N-D Tensor or numpy array\n",
    "        The element to shuffle. The last two dimensions must be (EEG_channel x EEG_samples), which means that the \n",
    "        same permutation is applied to all the channels of the EEG signal.\n",
    "    segments: int, optional\n",
    "        The number of segments in which the last dimension of x must be divided. Must be greater than 1\n",
    "        Default: 1\n",
    "    seg_to_per: int, optional\n",
    "        The number of segments to permute. Must be greater than 1 and lower than segments. -1 is the only\n",
    "        accepted negative number and means permute all the segments.\n",
    "        Default: -1\n",
    "    batch_equal: bool, optional\n",
    "        whether to apply the same permutation to all EEG record or not. If True, permute_signal is called \n",
    "        recursively for each dimension of the batch until the last two are reached (e.g. given a tensor x\n",
    "        of dimension (16,8,64,512) the function permute each of the 16*8 EEG signals (64 channels of 512 samples)\n",
    "        individually).\n",
    "        Default: False\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if segments<1:\n",
    "        raise ValueError('segments cannot be less than 2')     \n",
    "    if seg_to_per<1:\n",
    "        if seg_to_per>=0:\n",
    "            raise ValueError('seg_to_per must be bigger than 1 (put -1 to permute all segments)')\n",
    "        elif seg_to_per==-1:\n",
    "            seg_to_per=segments\n",
    "        elif (seg_to_per<(-1)):\n",
    "            msgError='got a negative number of segments to permute. Only -1 to permute all segments is allowed'\n",
    "            raise ValueError(msgError)\n",
    "    elif seg_to_per>segments:\n",
    "        raise ValueError('number of segment to permute is bigger than the number of segment')\n",
    "    \n",
    "    Ndim=len(x.shape)\n",
    "    if (Ndim<=2) or (batch_equal):\n",
    "        \n",
    "        segment_len= x.shape[-1] // segments\n",
    "        idx1=np.arange(segments)\n",
    "        np.random.shuffle(idx1)\n",
    "        idx2 = np.sort(idx1[:seg_to_per])\n",
    "        idx1=np.sort(idx1)\n",
    "        idx3 = np.copy(idx2)\n",
    "        while len(np.where(idx2==idx3)[0])>0:\n",
    "            np.random.shuffle(idx3)\n",
    "        idx1[idx2]=idx3\n",
    "        full_idx = np.arange(x.shape[-1])\n",
    "        for k in range(len(idx1)):\n",
    "            if idx1[k]!= k:\n",
    "                start=segment_len*idx1[k]\n",
    "                start2 = segment_len*k\n",
    "                newidx = np.arange(start, start+segment_len)\n",
    "                full_idx[start2: start2+segment_len]= newidx\n",
    "                \n",
    "        if not(isinstance(x, np.ndarray)):\n",
    "               full_idx=torch.from_numpy(full_idx).to(device=x.device)\n",
    "        x2 = x[..., full_idx]\n",
    "    \n",
    "    else:\n",
    "        x2 = np.empty_like(x) if isinstance(x, np.ndarray) else torch.empty_like(x)\n",
    "        for i in range(x.shape[0]):\n",
    "            x2[i] = permutation_signal(x[i], segments=segments, seg_to_per=seg_to_per, batch_equal=batch_equal)\n",
    "            \n",
    "    return x2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd5599",
   "metadata": {},
   "source": [
    "## Crop and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0286e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_pchip(x: \"1D Tensor\", \n",
    "                y: \"ND Tensor\", \n",
    "                xv: \"1D Tensor\",\n",
    "                save_memory: bool=True,\n",
    "                new_y_max_numel: int=4194304\n",
    "               ):\n",
    "    \"\"\"\n",
    "    torch_pchip perform pchip interpolation on the last dimension of the input tensor y.\n",
    "    \n",
    "    This function is a pytorch adaptation of the scipy's pchip_interpolate. It performs sp-pchip interpolation\n",
    "    (Shape Preserving Piecewise Cubic Hermite Interpolating Polynomial) on the last dimension of the y tensor.\n",
    "    x is the original time grid and xv new virtual grid. So, the new values of y at time xv are given by the \n",
    "    polynomials evaluated at the time grid x.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    x: 1D Tensor\n",
    "        Tensor with the original time grid. Must be the same length as the last dimension of y\n",
    "    y: ND Tensor\n",
    "        Tensor to interpolate. The last dimension must have the signals to interpolate\n",
    "    xv: 1D Tensor\n",
    "        Tensor with the new virtual grid, i.e. the time points where to interpolate\n",
    "    save_memory: bool, optional\n",
    "        whether to perform the interpolation on subsets of the y tensor by recursively function calls or not.\n",
    "        Does not apply if y is a 1-D tensor. If set to False memory usage can drastically increase \n",
    "        (for example with a 128 MB tensor, the memory usage of the function is 1.2 GB), but in some devices \n",
    "        it can speed up the process. However, this is not the case for all devices and performance may increase\n",
    "        (see example below run on an old computer).\n",
    "        Default: True\n",
    "    new_y_max_numel: int, optional\n",
    "        The number of elements which the tensor needs to surpass to make the function starting recursive calls.\n",
    "        It can be considered as an indicator of the maximum allowed memory usage since slower the number, slower\n",
    "        the memory used. \n",
    "        Default: 256*1024*16 (approximately 16s of recording of a 256 Channel EEG sampled at 1024 Hz)\n",
    "    \n",
    "    \n",
    "    Some technical information and difference with other interpolation:\n",
    "        https://blogs.mathworks.com/cleve/2012/07/16/splines-and-pchips/\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.PchipInterpolator.html\n",
    "    Some parts of the code are inspired from: \n",
    "        https://github.com/scipy/scipy/blob/v1.10.1/scipy/interpolate/_cubic.py#L157-L302\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    # result on my (old) computer with a 4D tensor/array with dim (1024,1,96,512) and xv with dim (1024,)\n",
    "    #         torch_pchip no save memory | torch_pchip save memory | scipy pchip_interpolate\n",
    "    #                   15.48s                     5.33s                     21.96s\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x.shape)!= 1:\n",
    "        raise ValueError(['Expected 1D Tensor for x but received a ', str(len(x.shape)), '-D Tensor']) \n",
    "    if len(xv.shape)!= 1:\n",
    "        raise ValueError(['Expected 1D Tensor for xv but received a ', str(len(xv.shape)), '-D Tensor'])\n",
    "    if x.shape[0] != y.shape[-1]:\n",
    "        raise ValueError('x must have the same length than the last dimension of y')\n",
    "\n",
    "    # Initialize the new interpolated tensor\n",
    "    Ndim=len(y.shape)\n",
    "    new_y=torch.empty(( *y.shape[:(Ndim-1)], xv.shape[0]))\n",
    "    \n",
    "    # If save_memory and the new Tensor size is huge, call recursively for each element in the first dimension \n",
    "    if save_memory:\n",
    "        if Ndim>1:\n",
    "            if ((torch.numel(y)/y.shape[-1])*xv.shape[0])>new_y_max_numel:\n",
    "                for i in range(new_y.shape[0]):\n",
    "                    new_y[i] = torch_pchip(x, y[i], xv)\n",
    "                return new_y\n",
    "    \n",
    "    \n",
    "    # This is a common part for every channel\n",
    "    bucket = torch.bucketize(xv, x) -1\n",
    "    bucket = torch.clamp(bucket, 0, x.shape[0]-2)\n",
    "    tv_minus = (xv - x[bucket]).unsqueeze(1)\n",
    "    infer_tv = torch.cat(( tv_minus**3, tv_minus**2, tv_minus, torch.ones(tv_minus.shape)  ), 1) \n",
    "    \n",
    "    \n",
    "    h = (x[1:]-x[:-1])\n",
    "    Delta = (y[...,1:] - y[...,:-1]) /h\n",
    "    k = (torch.sign(Delta[...,:-1]*Delta[...,1:]) > 0)\n",
    "    w1 = 2*h[1:] + h[:-1]\n",
    "    w2 = h[1:] + 2*h[:-1]\n",
    "    whmean = (w1/Delta[...,:-1] + w2/Delta[...,1:]) / (w1 + w2)\n",
    "    \n",
    "    slope = torch.zeros(y.shape)\n",
    "    slope[...,1:-1][k] = whmean[k].reciprocal()\n",
    "\n",
    "    slope[...,0] = ((2*h[0]+h[1])*Delta[...,0] - h[0]*Delta[...,1])/(h[0]+h[1])\n",
    "    slope_cond = torch.sign(slope[...,0]) != torch.sign(Delta[...,0])\n",
    "    slope[...,0][slope_cond] = 0\n",
    "    slope_cond = torch.logical_and( torch.sign(Delta[...,0]) != torch.sign(Delta[...,1]), \n",
    "                                   torch.abs(slope[...,0]) > torch.abs(3*Delta[...,0]) )\n",
    "    slope[...,0][ slope_cond ] = 3*Delta[...,0][slope_cond]\n",
    "    \n",
    "    slope[...,-1] = ((2*h[-1]+h[-2])*Delta[...,-1] - h[-1]*Delta[...,-2])/(h[-1]+h[-2])\n",
    "    slope_cond = torch.sign(slope[...,-1]) != torch.sign(Delta[...,-1])\n",
    "    slope[...,-1][ slope_cond ] = 0\n",
    "    slope_cond = torch.logical_and( torch.sign(Delta[...,-1]) != torch.sign(Delta[...,-1]), \n",
    "                                   torch.abs(slope[...,-1]) > torch.abs(3*Delta[...,1]) )\n",
    "    slope[...,-1][ slope_cond ] = 3*Delta[...,-1][slope_cond]\n",
    "\n",
    "\n",
    "    t = (slope[...,:-1] + slope[...,1:] - Delta - Delta)  / h \n",
    "    a = ( t )/ h\n",
    "    b = (Delta - slope[...,:-1]) / h - t\n",
    "    \n",
    "    \n",
    "\n",
    "    py_coef = torch.stack((a, b, slope[...,:-1], y[...,:-1]),-1)\n",
    "    new_y = (py_coef[...,bucket,:] * infer_tv ).sum(axis=-1)\n",
    "    \n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a658af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_signal(x,\n",
    "                segments: int=10,\n",
    "                stretch_strength: float=2.,\n",
    "                squeeze_strength: float=0.5,\n",
    "                batch_equal: bool=False,\n",
    "               ):\n",
    "    \n",
    "    \"\"\"\n",
    "    crop_and_resize crop some segments of the last dimension of the input x and resize to the original dimension.\n",
    "    \n",
    "    Given x a N-D Tensor where the last two dim are EEG_Channel x EEG_Signal, crop_and_resize:\n",
    "    1) divide the last dimension of x into N segments\n",
    "    2) select at random a subset segments\n",
    "    3) remove the selected segments from x\n",
    "    4) create a new cropped version of x\n",
    "    5) resample the new cropped version to the original dimension. For this part pchip interpolation \n",
    "       with a uniform virtual grid is used\n",
    "    If batch_equal is set to False, call the function recursively and repeat step 1 to 5 for each \n",
    "    (N_{1}*N_{2}...*N{-3}) elements of the tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : N-D Tensor or numpy array\n",
    "        The array to crop and resize. It accepts any dimensions but the last 2 must be EEG_Channel x EEG_Signal.\n",
    "        For example, if x is 4-D, it must be in the form (N1 x N2 x Channels x Signal), where N1 and N2 are usually\n",
    "        the batch size and channels\n",
    "    segments : int, optional\n",
    "        The number of segments to consider when dividing the last dimension of x.\n",
    "        Default: 10\n",
    "    N_cut : int, optional\n",
    "        The number of segments to cut. \n",
    "        Default: 1\n",
    "    batch_equal: bool, optional\n",
    "        whether to apply the same crop to all EEG record or not. True means faster computation but more memory\n",
    "        consuption and less variability, False the opposite\n",
    "        Default: False\n",
    "    \"\"\"\n",
    "    \n",
    "    Ndim=len(x.shape)\n",
    "    x_warped_final= np.empty_like(x) if isinstance(x, np.ndarray) else torch.empty_like(x, device=x.device)\n",
    "    \n",
    "    if batch_equal or Ndim<3:\n",
    "\n",
    "        # set segment do stretch squeeze\n",
    "        seglen= x.shape[-1] / segments\n",
    "        seg_range = np.arange(segments)\n",
    "        stretch = np.random.choice(seg_range, random.randint(1, segments//2), replace=False)\n",
    "        squeeze = np.setdiff1d(seg_range, stretch)\n",
    "\n",
    "        # pre-allocate warped vector to avoid continuous stack call\n",
    "        Lseg = np.zeros((segments,2), dtype=int)\n",
    "        Lseg[:,0] = (seg_range*seglen).astype(int)\n",
    "        Lseg[:,1] = ( (seg_range+1)*seglen).astype(int)\n",
    "        Lseg = Lseg[:,1] - Lseg[:,0]\n",
    "        Lsegsum = np.cumsum(Lseg)\n",
    "\n",
    "        x_size= [int(i) for i in x.shape]\n",
    "        warped_len = int(np.sum(np.ceil(Lseg[stretch]*stretch_strength)) + \n",
    "                         np.sum(np.ceil(Lseg[squeeze]*squeeze_strength)) )\n",
    "        x_size[-1]=warped_len\n",
    "\n",
    "        # initialize warped array (i.e. the array where to allocate stretched and squeezed segments)\n",
    "        x_warped = np.empty(x_size) if isinstance(x, np.ndarray) else torch.empty(x_size, device=x.device)\n",
    "        \n",
    "        # iterate over segments and stretch or squeeze each segment, then allocate to x_warped\n",
    "        idx_cnt=0\n",
    "        for i in range(segments):\n",
    "\n",
    "            piece = x[..., int(i * seglen):int( (i + 1) * seglen)]\n",
    "            if i in stretch:\n",
    "                new_piece_dim = int(np.ceil(piece.shape[-1] * stretch_strength))\n",
    "            else:\n",
    "                new_piece_dim = int(np.ceil(piece.shape[-1] * squeeze_strength))\n",
    "\n",
    "            if isinstance(x, np.ndarray):\n",
    "                warped_piece = interpolate.pchip_interpolate(np.linspace(0, seglen-1, piece.shape[-1]), piece, \n",
    "                                                             np.linspace(0, seglen-1, new_piece_dim), axis=-1)\n",
    "            else:\n",
    "                warped_piece = torch_pchip( torch.linspace(0, seglen-1, piece.shape[-1]), piece, \n",
    "                                            torch.linspace(0, seglen-1, new_piece_dim))\n",
    "\n",
    "            x_warped[..., idx_cnt : idx_cnt+new_piece_dim]=warped_piece\n",
    "            idx_cnt += new_piece_dim\n",
    "            \n",
    "        # resample x_warped to fit original size\n",
    "        if isinstance(x_warped, np.ndarray):\n",
    "            x_warped_final = interpolate.pchip_interpolate(np.linspace(0, warped_len-1, warped_len), x_warped, \n",
    "                                                             np.linspace(0, warped_len-1, x.shape[-1]), axis=-1)\n",
    "        else:\n",
    "            x_warped_final = torch_pchip(torch.linspace(0, warped_len-1, warped_len), x_warped, \n",
    "                                         torch.linspace(0, warped_len, x.shape[-1]))\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # Recursively call until second to last dim is reached\n",
    "        for i in range(x.shape[0]):\n",
    "            x_warped_final[i] =  warp_signal(x[i] ,segments, stretch_strength,squeeze_strength, batch_equal)\n",
    "     \n",
    "    return x_warped_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef8ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_and_resize(x: 'N-D Tensor or array',\n",
    "                    segments: int=10,\n",
    "                    N_cut: int=1,\n",
    "                    batch_equal: bool=False,\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    crop_and_resize crop some segments of the last dimension of the input x and resize to the original dimension.\n",
    "    \n",
    "    Given x a N-D Tensor where the last two dim are EEG_Channel x EEG_Signal, crop_and_resize:\n",
    "    1) divide the last dimension of x into N segments\n",
    "    2) select at random a subset segments\n",
    "    3) remove the selected segments from x\n",
    "    4) create a new cropped version of x\n",
    "    5) resample the new cropped version to the original dimension. For this part pchip interpolation \n",
    "       with a uniform virtual grid is used\n",
    "    If batch_equal is set to False, call the function recursively and repeat step 1 to 5 for each \n",
    "    (N_{1}*N_{2}...*N{-3}) elements of the tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : N-D Tensor or numpy array\n",
    "        The array to crop and resize. It accepts any dimensions but the last 2 must be EEG_Channel x EEG_Signal.\n",
    "        For example, if x is 4-D, it must be in the form (N1 x N2 x Channels x Signal), where N1 and N2 are usually\n",
    "        the batch size and channels\n",
    "    segments : int, optional\n",
    "        The number of segments to consider when dividing the last dimension of x.\n",
    "        Default: 10\n",
    "    N_cut : int, optional\n",
    "        The number of segments to cut. \n",
    "        Default: 1\n",
    "    batch_equal: bool, optional\n",
    "        whether to apply the same crop to all EEG record or not. True means faster computation but more memory\n",
    "        consuption and less variability, False the opposite\n",
    "        Default: False\n",
    "        \n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    dim = (16,1,64,512)\n",
    "    segments=15\n",
    "    N_cut=6\n",
    "    \n",
    "    x = torch.sin(torch.linspace(0,20*math.pi, dim[-1]))\n",
    "    zero_tensor = torch.zeros(dim)\n",
    "    x = zero_tensor + x\n",
    "    # x = x.numpy() #the result won't change if x is a numpy array\n",
    "    \n",
    "    x_crop = crop_and_resize(x, segments= segments, N_cut= N_cut, batch_equal=True)\n",
    "    print(torch.equal(x_crop[1], x_crop[2])) # True\n",
    "    x_crop = crop_and_resize(x, segments= segments, N_cut= N_cut, batch_equal=False)\n",
    "    print(torch.equal(x_crop[1], x_crop[2])) # False\n",
    "    \n",
    "    # plot the results\n",
    "    plt.plot(xnp[0,0,0,:])\n",
    "    plt.show()\n",
    "    plt.plot(x_crop[0,0,0,:])\n",
    "    plt.plot(x_crop[2,0,0,:])\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    x_crop=np.empty_like(x) if isinstance(x, np.ndarray) else torch.empty_like(x, device=x.device)\n",
    "    Ndim = len(x.shape)\n",
    "    if batch_equal or Ndim<3:\n",
    "        \n",
    "        segment_len= x.shape[-1] // segments\n",
    "        if isinstance(x, np.ndarray):\n",
    "            seg_to_rem = np.random.randint(0,segments, N_cut, dtype=int)\n",
    "            idx_to_rem = np.empty(segment_len*N_cut, dtype=int)\n",
    "            for i in range(seg_to_rem.shape[0]):\n",
    "                start=segment_len*(seg_to_rem[i])\n",
    "                idx1 = segment_len*i\n",
    "                idx_to_rem[idx1 : idx1+segment_len]= np.linspace(start, start+segment_len-1, segment_len)\n",
    "\n",
    "            new_x= np.delete(x, idx_to_rem, axis=-1)\n",
    "            x_crop = interpolate.pchip_interpolate(np.linspace(0, x.shape[-1]-1, new_x.shape[-1]), \n",
    "                                                   new_x, np.linspace(0,x.shape[-1]-1,x.shape[-1]), axis=-1)\n",
    "        else:\n",
    "\n",
    "            seg_to_rem = torch.randperm(segments, device=x.device)[:N_cut]\n",
    "            idx_to_rem = torch.empty(segment_len*N_cut, dtype=torch.int, device=x.device)\n",
    "            for i in range(seg_to_rem.shape[0]):\n",
    "                start=segment_len*(seg_to_rem[i])\n",
    "                idx1 = segment_len*i\n",
    "                idx_to_rem[idx1 : idx1+segment_len]= torch.linspace(start, start+segment_len-1, segment_len, device=x.device)\n",
    "\n",
    "            # https://stackoverflow.com/questions/55110047/finding-non-intersection-of-two-pytorch-tensors\n",
    "            allidx = torch.arange(x.shape[-1], device=x.device)\n",
    "            combined = torch.cat( (allidx, idx_to_rem, idx_to_rem) )\n",
    "            uniques, counts = combined.unique(return_counts=True)\n",
    "            difference = uniques[counts == 1]\n",
    "            new_x= x[...,difference]\n",
    "            x_crop = torch_pchip(torch.linspace(0, x.shape[-1]-1, new_x.shape[-1]), \n",
    "                                 new_x, torch.linspace(0,x.shape[-1]-1,x.shape[-1]))\n",
    "    \n",
    "    else:\n",
    "        for i in range(x.shape[0]):\n",
    "            x_crop[i] = crop_and_resize(x[i], segments, N_cut, batch_equal)\n",
    "\n",
    "        \n",
    "    return x_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86480d81",
   "metadata": {},
   "source": [
    "# Augmentation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b62247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticSingleAug():\n",
    "    \n",
    "    def __init__(self, augmentation, arguments: list or dict or list[list or dict]=None):\n",
    "        \n",
    "        if not(inspect.isfunction(augmentation) or inspect.isbuiltin(augmentation)):\n",
    "            raise ValueError('augmentation must be a function to call')\n",
    "        else:\n",
    "            self.augmentation=augmentation\n",
    "        \n",
    "        self.arguments=arguments\n",
    "        self.counter=0\n",
    "        self.maxcounter=0\n",
    "        self.multipleStaticArguments=False\n",
    "        if arguments !=None:\n",
    "            if all(isinstance(i,list) or isinstance(i,dict) for i in arguments):\n",
    "                self.multipleStaticArguments=True\n",
    "                self.maxcounter=len(arguments)\n",
    "        \n",
    "    def PerformAugmentation(self, X):\n",
    "        \n",
    "        if self.multipleStaticArguments:\n",
    "            argument=self.arguments[self.counter]\n",
    "            if isinstance(argument, list):\n",
    "                Xaug = self.augmentation(X, *argument)\n",
    "            else:\n",
    "                Xaug = self.augmentation(X, **argument)\n",
    "            \n",
    "            self.counter +=1\n",
    "            if self.counter == self.maxcounter:\n",
    "                self.counter=0 \n",
    "            print(argument)\n",
    "        else:\n",
    "            if self.arguments==None:\n",
    "                Xaug= self.augmentation(X)\n",
    "            elif isinstance(self.arguments, list):\n",
    "                Xaug = self.augmentation(X, *self.arguments)\n",
    "            else:\n",
    "                Xaug = self.augmentation(X, **self.arguments)\n",
    "            print(self.arguments)\n",
    "        \n",
    "        return Xaug\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.PerformAugmentation(X)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e65ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicSingleAug():\n",
    "    def __init__(self, \n",
    "                 augmentation, \n",
    "                 discrete_arg: Dict[str, list]=None, \n",
    "                 range_arg: Dict[str, list[ int or float, int or float]]=None,\n",
    "                 range_type: Dict[str, str or bool] or list[str or bool]=None\n",
    "                ):\n",
    "        \n",
    "        # set augmentation function\n",
    "        if not(inspect.isfunction(augmentation) or inspect.isbuiltin(augmentation)):\n",
    "            raise ValueError('augmentation must be a function to call')\n",
    "        else:\n",
    "            self.augmentation=augmentation\n",
    "        \n",
    "        # get function argument name\n",
    "        self.argnames= inspect.getfullargspec(augmentation)[0][1:]\n",
    "        \n",
    "        # check if given discrete_arg keys are actually augmentation arguments\n",
    "        self.discrete_arg=None\n",
    "        if discrete_arg != None:\n",
    "            if isinstance(discrete_arg, dict):\n",
    "                if all(i in self.argnames for i in discrete_arg):\n",
    "                    self.discrete_arg=discrete_arg\n",
    "                else:\n",
    "                    raise ValueError('keys of discrete_arg argument must be the argument of the augmentation fun')\n",
    "            else:\n",
    "                raise ValueError('discrete_arg must be a dictionary')\n",
    "        \n",
    "        # check if given range_arg keys are actually augmentation arguments \n",
    "        # also check if values are two element list\n",
    "        self.range_arg=None\n",
    "        if range_arg != None:\n",
    "            if isinstance(range_arg, dict):\n",
    "                if all(i in self.argnames for i in range_arg):\n",
    "                    if all( (isinstance(i,list) and len(i)==2) for i in range_arg.values()):\n",
    "                        self.range_arg=range_arg\n",
    "                    else:\n",
    "                        raise ValueError('range_arg values must be a len 2 list with min and max range')\n",
    "                else:\n",
    "                    raise ValueError('keys of range_arg argument must be the argument of the augmentation fun')\n",
    "            else:\n",
    "                raise ValueError('range_arg must be a dictionary')\n",
    "        \n",
    "        # check if range_types keys are the same as range_args\n",
    "        self.range_type=None\n",
    "        if range_type!=None:\n",
    "            if isinstance(range_type, dict):\n",
    "                if range_type.keys() == range_arg.keys():\n",
    "                    self.range_type=range_type\n",
    "                else:\n",
    "                    raise ValueError('keys of range_type must be the same as range_arg')\n",
    "            elif isinstance(range_type, list):\n",
    "                if len(range_type)==len(self.range_arg):\n",
    "                    self.range_type=range_type\n",
    "                else:\n",
    "                    raise ValueError('range_type must have the same length as range_args')\n",
    "            else:\n",
    "                raise ValueError('discrete_arg must be a dictionary or a list')\n",
    "        self.is_range_type_dict= True if isinstance(self.range_type, dict) else False\n",
    "        \n",
    "        self.given_arg = list(self.discrete_arg) if self.discrete_arg!=None else []\n",
    "        self.given_arg += list(self.range_arg) if self.range_arg!=None else []\n",
    "        \n",
    "    \n",
    "    def PerformAugmentation(self, X):    \n",
    "        arguments={i:None for i in self.given_arg}\n",
    "        if self.discrete_arg!=None:\n",
    "            for i in self.discrete_arg:\n",
    "                if isinstance(self.discrete_arg[i],list): \n",
    "                    arguments[i] = random.choice(self.discrete_arg[i]) \n",
    "                else:\n",
    "                    arguments[i]= self.discrete_arg[i] \n",
    "        \n",
    "        cnt=0 # counter if range_type is a list, it's a sort of enumerate\n",
    "        if self.range_arg!=None:\n",
    "            for i in self.range_arg.keys():\n",
    "                arguments[i]=random.uniform(self.range_arg[i][0], self.range_arg[i][1])\n",
    "                if self.is_range_type_dict:\n",
    "                    if self.range_type[i] in ['int', True]:\n",
    "                        arguments[i] = int(arguments[i])\n",
    "                else:\n",
    "                    if self.range_type[cnt] in ['int', True]:\n",
    "                        arguments[i] = int(arguments[i])\n",
    "                    cnt+=1\n",
    "        \n",
    "        print(arguments)\n",
    "        Xaug = self.augmentation(X, **arguments)\n",
    "        return Xaug\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.PerformAugmentation(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5527e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialAug():\n",
    "    \n",
    "    def __init__(self,*augmentations):\n",
    "        \n",
    "        self.augs=[item for item in augmentations]\n",
    "     \n",
    "    def PerformAugmentation(self, X): \n",
    "        \n",
    "        Xaugs = self.augs[0](X)\n",
    "        for i in range(1,len(self.augs)):\n",
    "            Xaugs = self.augs[i](Xaugs)\n",
    "        return Xaugs\n",
    "            \n",
    "    def __call__(self, X):\n",
    "        return self.PerformAugmentation(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
