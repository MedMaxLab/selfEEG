{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb77a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47620e43",
   "metadata": {},
   "source": [
    "# Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a8362",
   "metadata": {},
   "source": [
    "### Special Kernels not implemented in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574af087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedConv2d(nn.Conv2d):\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.weight.clamp(min=0, max=1.0), self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "    \n",
    "class ConstrainedDense(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None, norm_rate=0.25):\n",
    "        super(ConstrainedDense, self).__init__(in_features, out_features, bias=bias, device=device, dtype=dtype)\n",
    "        self.norm_rate = norm_rate \n",
    "        \n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.weight.clamp(min=0,max=self.norm_rate), self.bias)\n",
    "    \n",
    "    \n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=False, padding='same'):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   groups=in_channels, bias=bias, padding=padding)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, \n",
    "                                   kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a3c83",
   "metadata": {},
   "source": [
    "## EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch Implementation of the EEGnet Encoder. For more information see the following paper:\n",
    "        Lawhern et al., EEGNet: a compact convolutional neural network for EEG-based \n",
    "        brain–computer interfaces. Journal of Neural Engineering. 2018\n",
    "    \n",
    "    Keras implementation of the full EEGnet (updated version) with more info at:\n",
    "        https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \n",
    "    NOTE: This implementation referres to the latest version of EEGNet which can be found in the \n",
    "    \"\"\"\n",
    "    def __init__(self, Chans, kernLength = 64, dropRate = 0.5, F1 = 8, \n",
    "                 D = 2, F2 = 16, ELUalpha=1, dropType = 'Dropout'):\n",
    "        \n",
    "        \n",
    "        if dropType not in ['SpatialDropout2D','Dropout']:\n",
    "            raise ValueError('implemented Dropout types are \\'Dropout\\' or \\'SpatialDropout2D \\'')\n",
    "        \n",
    "        super(EEGNetEncoder, self).__init__()\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1      = nn.Conv2d(1, F1, (1, kernLength), padding = 'same', bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(F1, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2      = ConstrainedConv2d(F1, D*F1, (Chans, 1), bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(D*F1, False)\n",
    "        self.elu2       = nn.ELU(alpha=ELUalpha)\n",
    "        self.pooling2   = nn.AvgPool2d((1,4))\n",
    "        self.drop2      = nn.Dropout(p=dropRate) if dropType.lower()=='dropout' else nn.Dropout2d(p=dropRate)\n",
    "\n",
    "        # Layer 3\n",
    "        self.sepconv3   = SeparableConv2d(D*F1, F2, (1,16), bias=False, padding='same')\n",
    "        self.batchnorm3 = nn.BatchNorm2d(F2, False)\n",
    "        self.elu3       = nn.ELU(alpha=ELUalpha)\n",
    "        self.pooling3   = nn.AvgPool2d((1,8))\n",
    "        self.drop3      = nn.Dropout(p=dropRate) if dropType.lower()=='dropout' else nn.Dropout2d(p=dropRate)\n",
    "        self.flatten3   = nn.Flatten()\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layer 1\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.elu2(x)\n",
    "        x = self.pooling2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.sepconv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.elu3(x)\n",
    "        x = self.pooling3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.flatten3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch Implementation of EEGnet. For more information see the following paper:\n",
    "        Lawhern et al., EEGNet: a compact convolutional neural network for EEG-based \n",
    "        brain–computer interfaces. Journal of Neural Engineering. 2018\n",
    "    \n",
    "    Keras implementation of the full EEGnet (updated version) with more info at:\n",
    "        https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py\n",
    "    \n",
    "    NOTE: This implementation referres to the latest version of EEGNet which can be found in the \n",
    "    \"\"\"\n",
    "    def __init__(self, nb_classes, Chans, Samples, dropRate = 0.5, kernLength = 64, F1 = 8, \n",
    "                 D = 2, F2 = 16, norm_rate = 0.25, ELUalpha=1, dropType = 'Dropout'):\n",
    "        \n",
    "        super(EEGNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.Encoder    = EEGNetEncoder(Chans, dropRate = dropRate, kernLength = kernLength, \n",
    "                                        F1 = F1, D = D, F2 = F2, ELUalpha=ELUalpha, dropType = dropType)\n",
    "        \n",
    "        # Classifier\n",
    "        self.Dense      = ConstrainedDense( F2*(Samples//32), nb_classes, norm_rate=norm_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.Encoder(x)\n",
    "        x=F.softmax(self.Dense(x),dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b16e4",
   "metadata": {},
   "source": [
    "## StagerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagerNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of the StagerNet Encoder. For more information see the following papaer:\n",
    "    Chambon et al., A deep learning architecture for temporal sleep stage classification \n",
    "    using multivariate and multimodal time series, arXiv:1707.03321\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Chans, kernLength = 64, F = 8, Pool = 16):\n",
    "        \n",
    "        super(StagerNetEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1      = nn.Conv2d(1, Chans, (Chans,1), stride=(1,1), bias=True)\n",
    "        self.conv2      = nn.Conv2d(1, F, (1,kernLength), stride=(1,1), padding='same')\n",
    "        self.pooling2   = nn.MaxPool2d((1,Pool), stride=(1,Pool))\n",
    "        self.conv3      = nn.Conv2d(F, F, (1,kernLength), stride=(1,1), padding='same')\n",
    "        self.pooling3   = nn.MaxPool2d((1,Pool), stride=(1,Pool))\n",
    "        self.flatten3   = nn.Flatten()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.permute(x, (0,2,1,3))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pooling2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pooling3(x)\n",
    "        x = self.flatten3(x) \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "class StagerNet(nn.Module):    \n",
    "    \"\"\"\n",
    "    Pytorch implementation of the StagerNet Encoder. For more information see the following papaer:\n",
    "    Chambon et al., A deep learning architecture for temporal sleep stage classification \n",
    "    using multivariate and multimodal time series, arXiv:1707.03321\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_classes, Chans, Samples, dropRate = 0.5, kernLength = 64, F = 8, Pool = 16):\n",
    "        \n",
    "        super(StagerNet, self).__init__()\n",
    "        \n",
    "        self.Encoder    = StagerNetEncoder(Chans, kernLength=kernLength, F = F, Pool = Pool)\n",
    "        \n",
    "        self.drop       = nn.Dropout(p=dropRate)\n",
    "        self.Dense      = nn.Linear(Chans*(Samples//256)*F, nb_classes )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.drop(x)\n",
    "        x = F.softmax(self.Dense(x), dim=1)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044f7c5",
   "metadata": {},
   "source": [
    "## ShallowNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fce0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of the Shallow ConvNet Encoder. For more information see the following papaer:\n",
    "    Schirrmeister et al., Deep Learning with convolutional neural networks for decoding and visualization \n",
    "    of EEG pathology, arXiv:1708.08012\n",
    "    \n",
    "    NOTE= In this implementation, the number of channels is an argument. However, in the original paper\n",
    "          they preprocess EEG data by selecting a subset of only 21 channels. Since the net is pretty\n",
    "          minimalist, we suggest to follow author notes\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Chans, F = 8, K1 = 25, Pool = 75):\n",
    "        \n",
    "        super(ShallowNetEncoder, self).__init__() \n",
    "        self.conv1      = nn.Conv2d(1, F, (1, K1), stride=(1,1))\n",
    "        self.conv2      = nn.Conv2d(F, F, (Chans, 1), stride=(1,1))\n",
    "        self.pool2      = nn.AvgPool2d((1, Pool), stride=(1,15))\n",
    "        self.flatten2   = nn.Flatten()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.log(x)\n",
    "        x = self.flatten2(x) \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ShallowNet(nn.Module):    \n",
    "    \"\"\"\n",
    "    Pytorch implementation of the Shallow ConvNet Encoder. For more information see the following papaer:\n",
    "    Schirrmeister et al., Deep Learning with convolutional neural networks for decoding and visualization \n",
    "    of EEG pathology, arXiv:1708.08012\n",
    "    \n",
    "    NOTE= In this implementation, the number of channels is an argument. However, in the original paper\n",
    "          they preprocess EEG data by selecting a subset of only 21 channels. Since the net is pretty\n",
    "          minimalist, we suggest to follow author notes\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_classes, Chans, Samples, F = 40, K1 = 25, Pool = 75):\n",
    "        \n",
    "        super(ShallowNet, self).__init__()\n",
    "        \n",
    "        self.Encoder    = ShallowNetEncoder(Chans, F = F, K1 = K1, Pool = Pool)\n",
    "        self.Dense     = nn.Linear(F*((Samples-K1+1-Pool)//15 +1), nb_classes )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.Encoder(x)\n",
    "        x = F.softmax(self.Dense(x), dim=1)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdd063",
   "metadata": {},
   "source": [
    "## ResNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d51f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockZheng(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernLength = 7, stride = 1):\n",
    "        \n",
    "        super(BasicBlockZheng, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=(1, kernLength), stride=(1, stride), \n",
    "                               padding=(0, kernLength//2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=(1, kernLength), stride=(1, 1), \n",
    "                               padding=(0, kernLength//2), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        if inplanes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=(1, kernLength), stride=(1, stride), \n",
    "                          padding=(0, kernLength//2), bias=False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        # print('residual: ', residual.shape)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # print('out 1: ', out.shape)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # print('out 2: ', out.shape)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet1DEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 Chans, \n",
    "                 block: nn.Module = BasicBlockZheng, \n",
    "                 Layers: \"list of 4 int\"=[2, 3, 4, 6], \n",
    "                 inplane: int=16, \n",
    "                 kernLength: int=7,\n",
    "                 addConnection: bool=True,\n",
    "                 preBlock: nn.Module=None,\n",
    "                 postBlock: nn.Module=None\n",
    "                ):\n",
    "        \n",
    "        super(ResNet1DEncoder, self).__init__()\n",
    "        self.inplane = inplane\n",
    "        self.kernLength = kernLength\n",
    "        self.connection = addConnection\n",
    "        \n",
    "        \n",
    "        #   PRE-RESIDUAL\n",
    "        if preBlock is None:\n",
    "            self.preBlocks = nn.Sequential(nn.Conv2d(1, self.inplane, kernel_size=(1, kernLength), stride=(1, 2),\n",
    "                                                    padding=(0, kernLength//2), bias=False),\n",
    "                                           nn.BatchNorm2d(self.inplane),\n",
    "                                           nn.ReLU(inplace=True)\n",
    "                                          )\n",
    "        else: \n",
    "            self.preBlocks = preBlock\n",
    "        \n",
    "        #  RESIDUAL BLOCKS\n",
    "        self.layer1  = self._make_layer(block, self.inplane, Layers[0], kernLength=kernLength, stride=1)\n",
    "        self.layer2  = self._make_layer(block, self.inplane * 2, Layers[1], kernLength=kernLength, stride=2)\n",
    "        self.layer3  = self._make_layer(block, self.inplane * 2, Layers[2], kernLength=kernLength, stride=2)\n",
    "        self.layer4  = self._make_layer(block, self.inplane * 2, Layers[3], kernLength=kernLength, stride=2)\n",
    "\n",
    "        #  POST-RESIDUAL\n",
    "        if postBlock is None:\n",
    "            self.postBlocks = nn.Sequential(nn.Conv2d(self.inplane, inplane, kernel_size=(1, kernLength), stride=(1, 1),\n",
    "                                                      padding=(0, 0), bias=False),\n",
    "                                            nn.AdaptiveAvgPool2d((Chans,1))\n",
    "                                           )\n",
    "        else:\n",
    "            self.postBlocks = postBlock\n",
    "        \n",
    "        # RESIDUAL SKIP CONNECTION\n",
    "        if self.connection:\n",
    "            self.conv3   = nn.Conv2d(inplane, 2, kernel_size=(Chans, kernLength), stride=(1, 3),\n",
    "                             padding=(0, 0), bias=False)\n",
    "        \n",
    "        # WEIGHT INITIALIZATION\n",
    "        self.initialize()\n",
    "        \n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, kernLength=7, stride=1, **kwarg):\n",
    "\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inplane, planes, kernLength, stride))\n",
    "            self.inplane = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "\n",
    "        x1 = self.preBlocks(x)\n",
    "        \n",
    "        x2 = self.layer1(x1)\n",
    "        x2 = self.layer2(x2)\n",
    "        x2 = self.layer3(x2)\n",
    "        x2 = self.layer4(x2)\n",
    "        x2 = self.postBlocks(x2)\n",
    "        out1 = x2.view(x2.size(0), -1)\n",
    "        \n",
    "        if self.connection:\n",
    "            out2 = self.conv3(x1)             \n",
    "            out2 = out2.view(out2.size(0), -1)\n",
    "            embeddings = torch.cat((out1, out2), dim=-1)\n",
    "        else:\n",
    "            embeddings = out1\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class ResNet1D(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 nb_classes, \n",
    "                 Chans, \n",
    "                 Samples, \n",
    "                 block: nn.Module, \n",
    "                 Layers: \"list of 4 int\" = [0, 0, 0, 0],\n",
    "                 inplane: int=16, \n",
    "                 kernLength: int=7,\n",
    "                 addConnection: bool=True,\n",
    "                 preBlock: nn.Module=None,\n",
    "                 postBlock: nn.Module=None,\n",
    "                 classifier: nn.Module=None,\n",
    "                ):\n",
    "        \n",
    "        super(ResNet1D, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.Encoder    = ResNet1DEncoder(Chans=Chans, block=block, Layers=Layers, inplane= inplane, \n",
    "                                          kernLength= kernLength, addConnection=addConnection, \n",
    "                                          preBlock= preBlock, postBlock=postBlock)\n",
    "        # Classifier\n",
    "        if classifier is None:\n",
    "            if addConnection:\n",
    "                self.Classifier = nn.Linear(Chans*inplane + (((Samples+1)//2 - kernLength)//3 + 1)*2, nb_classes)\n",
    "            else:\n",
    "                self.Classifier = nn.Linear(Chans*inplane, nb_classes)\n",
    "        else:\n",
    "            self.Classifier = classifier\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.Encoder(x)\n",
    "        x=F.softmax(self.Classifier(x), dim=1)\n",
    "        print('final output', x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb54d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 78, 256])\n",
      "pre layer:  torch.Size([16, 16, 78, 128])\n",
      "layer 1 out:  torch.Size([16, 16, 78, 128])\n",
      "layer 2 out:  torch.Size([16, 32, 78, 64])\n",
      "layer 3 out:  torch.Size([16, 64, 78, 32])\n",
      "layer 4 out:  torch.Size([16, 128, 78, 16])\n",
      "resnet output to concatenate torch.Size([16, 1248])\n",
      "start to end connection output to concatenate  torch.Size([16, 80])\n",
      "final embeddings torch.Size([16, 1328])\n",
      "final output torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "kl=11\n",
    "inpl=16\n",
    "ch=78\n",
    "smpl=256\n",
    "Layer= [2,3,4,6]\n",
    "Xtest=torch.randn((16,ch,smpl))\n",
    "Net = ResNet1D(5, ch, smpl, BasicBlockZheng, Layers=Layer, inplane= inpl, kernLength= kl )\n",
    "#Net = ResNet34(18, BasicBlockZheng, Layers=[3,4,6,3], inplane= 16, kernLength= 7 )\n",
    "output = Net(Xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
