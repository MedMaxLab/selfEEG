{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6056e6-86ea-4c92-9e95-a64b38d6f4c9",
   "metadata": {},
   "source": [
    "# Build a self-supervised learning pipeline\n",
    "\n",
    "This notebook will explain how to use the selfeeg library to build a self-supervised learning pipeline. \n",
    "\n",
    "To summarize, typical steps include:\n",
    "\n",
    "1. [PRETRAINING](#Pretraining-Phase):\n",
    "    1. [define the pretraining dataloaders](#Define-Dataloaders)\n",
    "    2. [define the augmenter](#Define-the-data-augmenter)\n",
    "    3. [define the pretraining model](#Define-pretraining-model-and-other-training-objects) (and optional training elements)\n",
    "    4. [pretrain the model](#Pretrain-the-model)\n",
    "2. [FINE-TUNING](#Fine-tuning-Phase)\n",
    "    1. [define the fine-tuning dataloaders](#Define-fine-tuning-dataloaders)\n",
    "    2. [define the fine-tuning model](#Define-fine-tuning-model-and-other-training-objects) (and optional training elements)\n",
    "    3. [transfer the pretrained encoder's weights](#Define-fine-tuning-model-and-other-training-objects)\n",
    "    4. [fine-tune the model](#Fine-tuning)\n",
    "3. [FINAL EVALUATION](#Evaluate-fine-tuned-model)\n",
    "\n",
    "To better understand how the **dataloading** and **augmentations** module work, check the respective introductory notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813d14e-e23b-4cec-8490-6e92ed1bc02a",
   "metadata": {},
   "source": [
    "First, let's import all the packages necessary to run this notebook.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>WARNING</b> \n",
    "    \n",
    "to run this notebook you will also need <b>matplotlib</b>, which are not listed in the main dependecies of the selfeeg library. Be sure to install them in your environment.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732513d-39eb-4ddd-a6de-51e9574e515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT BASE PACKAGES\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('..')  # needed if you run this inside the selfeeg/doc folder\n",
    "\n",
    "import selfeeg\n",
    "import selfeeg.augmentation as aug\n",
    "import selfeeg.dataloading as dl\n",
    "\n",
    "# IMPORT CLASSICAL PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Draw figures inline with this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# IMPORT TORCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# set seeds for reproducibility\n",
    "seed = 1234\n",
    "random.seed( seed )\n",
    "np.random.seed( seed )\n",
    "torch.manual_seed( seed )\n",
    "plt.style.use('seaborn-v0_8-white')\n",
    "plt.rcParams['figure.figsize'] = (15.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969bdb4c-fc43-48ca-aac0-3a4bbfa898d4",
   "metadata": {},
   "source": [
    "## Pretraining Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f25ac-e564-45df-9fb2-76edd8665d11",
   "metadata": {},
   "source": [
    "### Create simulated data\n",
    "\n",
    "Similarly to the dataloading introductory notebook. We will create a dataset with simulated EEG samples.\n",
    "\n",
    "EEG files will be stored in the format `\"{dataset_id}_{subject_id}_{session_id}_{trial_id}.pickle\"`. Also, EEG files will contain a dict with keys:\n",
    "1) data: the **EEG** with **16 Channels** , random legnth **from 512 to 1024**, sampling rate **128 Hz**\n",
    "2) label: a binary label with **0 = normal EEG** and **1 = abnormal (epileptic) EEG**. Class ratio is 80\\% normal and 20\\% abnormal.\n",
    "\n",
    "EEG files will be generated using an order-1 AutoRegressive model. Coefficients were calculated using a channel acquisition from two real EEGs, one for each category. \n",
    "\n",
    "The following cell will create a folder with simulated 1000 EEGs coming from:\n",
    "1) 5 datasets (ID from 1 to 5);\n",
    "2) 40 subjects per dataset (ID from 1 to 40)\n",
    "3) 5 session per subject (ID from 1 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b27b59-cbb0-46ba-b51e-572f397d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = selfeeg.utils.create_dataset(p=0.6,return_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a7253-65e1-4ace-afc7-9c2c8fcadc2c",
   "metadata": {},
   "source": [
    "### Define dataloaders\n",
    "\n",
    "Let's assume we want to pretrain our model with the first four datasets, and evaluate it on the fifth.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>NOTE 1</b> \n",
    "    \n",
    "In this phase, it is suggested to put the fine-tuning data in the test set. In this way, it will be easier to extract the subtables with only the fine-tuning samples.\n",
    "\n",
    "</div>\n",
    "\n",
    "Since each EEG will have a different length, we will use 2s windows with 10\\% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862b8c0-b7cc-466c-ac51-5aa35daff630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file path, sampling rate, window length, overlap percentage, workers and batch size\n",
    "eegpath = 'Simulated_EEG'\n",
    "Chan = 8\n",
    "freq = 128\n",
    "window = 2\n",
    "overlap = 0.1\n",
    "workers = 0\n",
    "batchsize = 16\n",
    "\n",
    "# define custom loading function\n",
    "def loadEEG(path, return_label=False):\n",
    "    with open(path, 'rb') as eegfile:\n",
    "        EEG = pickle.load(eegfile)\n",
    "    x = EEG['data']\n",
    "    y = EEG['label']\n",
    "    if return_label:\n",
    "        return x, y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# calculate dataset length\n",
    "EEGlen = dl.GetEEGPartitionNumber(eegpath, freq, window, overlap, file_format='*.pickle', \n",
    "                                  load_function=loadEEG, verbose = True)\n",
    "\n",
    "# split dataset\n",
    "EEGsplit= dl.GetEEGSplitTable(partition_table=EEGlen, val_ratio= 0.1, stratified=True, labels=classes,\n",
    "                              test_data_id=[5], split_tolerance=0.001, perseverance=10000)\n",
    "\n",
    "# check split\n",
    "dl.check_split(EEGlen, EEGsplit, classes)\n",
    "\n",
    "# define training dataloader\n",
    "trainset = dl.EEGDataset(EEGlen, EEGsplit, [freq, window, overlap], load_function=loadEEG)\n",
    "trainsampler = dl.EEGsampler(trainset, batchsize, workers)\n",
    "trainloader = DataLoader(dataset = trainset, batch_size= batchsize, sampler=trainsampler, num_workers=workers)\n",
    "\n",
    "# define validation dataloader\n",
    "valset = dl.EEGDataset(EEGlen, EEGsplit, [freq, window, overlap], 'validation', load_function=loadEEG)\n",
    "valloader = DataLoader(dataset = valset, batch_size= batchsize, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415f14b-4d59-4628-a2f1-d81e2d3d414f",
   "metadata": {},
   "source": [
    "### Define the data augmenter\n",
    "\n",
    "Now we need to define an augmenter. To keep things simple, we define an augmenter which combines:\n",
    "\n",
    "1. the addition of some noise or channel lost from ``add_band_noise`` or ``masking``\n",
    "2. the ``warp`` or ``crop_and_resize`` augmentation\n",
    "3. a final rescale of the range [-500, 500] uV in [-1, 1] with soft clipping with horizontal asintote of 1.5\n",
    "\n",
    "This is similar to the augmentation proposed in the augmentation module introductory book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f5a53-01b8-4e2f-9b95-9eb0b719030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE AUGMENTER\n",
    "# First block: noise addition\n",
    "AUG_band = aug.DynamicSingleAug(aug.add_band_noise, \n",
    "                                 discrete_arg={'bandwidth': [\"delta\", \"theta\", \"alpha\", \"beta\", (30,49) ], \n",
    "                                               'samplerate': freq,'noise_range': 0.5}\n",
    "                               )\n",
    "AUG_mask = aug.DynamicSingleAug(aug.masking, discrete_arg = {'mask_number': [1,2,3,4], 'masked_ratio': 0.25})\n",
    "Block1 = aug.RandomAug( AUG_band, AUG_mask, p=[0.7, 0.3])\n",
    "\n",
    "# second block: warp or crop and resize\n",
    "AUG_crop = aug.DynamicSingleAug(aug.crop_and_resize, discrete_arg={'batch_equal': False},\n",
    "                                range_arg ={'N_cut': [1, 4], 'segments': [10,15]}, range_type =[True, True]\n",
    "                               )\n",
    "AUG_warp = aug.DynamicSingleAug(aug.warp_signal, discrete_arg = {'batch_equal': [True, False]},\n",
    "                                range_arg= {'segments': [5,10], 'stretch_strength': [1.75,2.25],\n",
    "                                            'squeeze_strength': [0.45,0.55]},\n",
    "                                range_type=[True, False, False]\n",
    "                               )\n",
    "Block2 = aug.RandomAug( AUG_crop, AUG_warp)\n",
    "\n",
    "# third block: rescale\n",
    "Block3 = lambda x: selfeeg.utils.scale_range_soft_clip(x, 500, 1.2, 'uV', True)\n",
    "\n",
    "# FINAL AUGMENTER: SEQUENCE OF THE THREE RANDOM LISTS\n",
    "Augmenter = aug.SequentialAug(Block1, Block2, Block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c01e0-1701-4c02-b908-b523fba80620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a random data augmentation\n",
    "Sample = trainset.__getitem__(random.randint(0,len(trainset)))\n",
    "t = np.linspace(0, Sample.shape[1]-1, Sample.shape[1])/freq\n",
    "SampleAug = Augmenter(Sample)\n",
    "RandChan= random.randint(0,Chan-1)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('time [s]', fontsize=15)\n",
    "ax1.set_ylabel('[uV]', color=color, fontsize=15)\n",
    "ax1.plot(t,  Sample[RandChan,:], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color, labelsize=15)\n",
    "ax1.tick_params(axis='x', labelsize=15)\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('[ ]', color=color, fontsize=15)  # we already handled the x-label with ax1\n",
    "ax2.plot(t, SampleAug[RandChan,:],color=color, linewidth=2.5)\n",
    "ax2.tick_params(axis='y', labelsize=15, labelcolor=color)\n",
    "plt.title('Same random channel from one sample: augmented version', fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fd97f-e732-4a2e-82be-eaac4c0db58a",
   "metadata": {},
   "source": [
    "### Define pretraining model and other training objects\n",
    "\n",
    "Now we need to define the pretraining model. To do that, one must:\n",
    "\n",
    "1. instantiate an nn.Module defining the encoder (backbone)\n",
    "2. instantiate the right SSL module, giving the encoder and the network head's spec.\n",
    "\n",
    "For now, let's use a simple EEGNet with default parameters, and SimCLR as the SSL algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>NOTE 1</b> \n",
    "    \n",
    "each model in the <b>models</b> module have an extra class with only the encoder with the name <b>modelnameEncoder</b> (e.g., EEGNetEncoder). This will make model creation much easier. \n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>NOTE 2</b> \n",
    "    \n",
    "each model in the <b>ssl</b> module can accept a list or a nn.Module to create the network head. In case of a list, the head will be a sequence of dense layer with input and output size equal to the values of the list. Batchnorm and activation are based on the original works.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>WARNING</b> \n",
    "    \n",
    "Remember to check if the encoder output size matches the head input size. All modules in the ssl class doesn't check that.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a6e7e-98dd-4c4c-8884-295c7b523103",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Encoder\n",
    "NNencoder= selfeeg.models.ShallowNetEncoder(Chans=Chan, F=8)\n",
    "NNencoder2= copy.deepcopy(NNencoder) # It's suggested to copy the random initialization for embedding analysis\n",
    "\n",
    "# SSL model\n",
    "head_size=[ 88, 64, 64]\n",
    "SelfMdl = selfeeg.ssl.SimCLR(encoder=NNencoder, projection_head=head_size).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=selfeeg.losses.SimCLR_loss\n",
    "loss_arg={'temperature': 0.5}\n",
    "\n",
    "# earlystopper\n",
    "earlystop = selfeeg.ssl.EarlyStopping(patience=25, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-3)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e211933-5c74-4acc-8cf3-99730f6c8fcf",
   "metadata": {},
   "source": [
    "### Pretrain the model\n",
    "\n",
    "Each SSL algorithm has an already implemented fit method, similar to scikitlearn or Keras. Of course it's not complete as the fit of bigger framewoks, but it certainly save you lots of lines of code and help you monitorate the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a4a30-365f-4713-a6db-5617edfaabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss, loss_args= loss_arg,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=True, device= device, return_loss_info=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08381a75-fbe4-4153-b482-1934eaa2d2bb",
   "metadata": {},
   "source": [
    "## Fine-tuning Phase\n",
    "\n",
    "Now that the encoder is pretrained, let's perform fine-tuning. To do that, we need to recreate the right dataloaders and models. After that, the **selfeeg** library provides a **fine-tuning** function that is similar to the fit method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8dc32-4b9a-45cd-9615-77f2ff00c3a8",
   "metadata": {},
   "source": [
    "### Define fine-tuning dataloaders\n",
    "\n",
    "This phase is basically the same as the previous one. The only differences are:\n",
    "\n",
    "1. We are using the fine-tuning data\n",
    "2. We are creating a test set for evaluation\n",
    "3. We need to extract a label from each sample.\n",
    "\n",
    "The used classes and methods are the same already used from the dataloading module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a2c11-b6e7-4898-91bb-c7a19d096129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the samples for fine-tuning\n",
    "filesFT= EEGsplit.loc[EEGsplit['split_set']==2, 'file_name'].values\n",
    "EEGlenFT= EEGlen.loc[EEGlen['file_name'].isin(filesFT)].reset_index().drop(columns=['index'])\n",
    "labels = classes[ EEGsplit[EEGsplit['split_set']==2].index.tolist()]\n",
    "\n",
    "# split the fine-tuning data in train-test-validation\n",
    "EEGsplitFT = dl.GetEEGSplitTable(partition_table=EEGlenFT, test_ratio = 0.2, val_ratio= 0.1, val_ratio_on_all_data=False,\n",
    "                                 stratified=True, labels=labels, split_tolerance=0.001, perseverance=10000)\n",
    "\n",
    "# TRAINING DATALOADER\n",
    "trainsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'train', \n",
    "                           supervised=True, label_on_load=True, \n",
    "                           load_function=loadEEG, optional_load_fun_args=[True])\n",
    "trainsamplerFT = dl.EEGsampler(trainsetFT, batchsize, workers)\n",
    "trainloaderFT = DataLoader(dataset = trainsetFT, batch_size= batchsize, sampler=trainsamplerFT, num_workers=workers)\n",
    "\n",
    "# VALIDATION DATALOADER\n",
    "valsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'validation', \n",
    "                         supervised=True, label_on_load=True, \n",
    "                         load_function=loadEEG, optional_load_fun_args=[True])\n",
    "valloaderFT = DataLoader(dataset = valsetFT, batch_size= batchsize, num_workers=workers, shuffle=False)\n",
    "\n",
    "#TEST DATALOADER\n",
    "testsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'test', \n",
    "                          supervised=True, label_on_load=True, \n",
    "                          load_function=loadEEG, optional_load_fun_args=[True])\n",
    "testloaderFT = DataLoader(dataset = testsetFT, batch_size= batchsize, shuffle=False)\n",
    "\n",
    "dl.check_split(EEGlenFT, EEGsplitFT, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb4ed0-f149-4a62-9d1d-ba32c0895c9f",
   "metadata": {},
   "source": [
    "### Define fine-tuning model and other training objects\n",
    "\n",
    "Remember that in this phase you need to transfer the pretrained encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb89f11-7ade-4722-b3b5-78f24cc34665",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalMdl = selfeeg.models.ShallowNet(nb_classes = 2, Chans = Chan, Samples = int(freq*window), F=8)\n",
    "\n",
    "# Transfer the pretrained backbone and move the final model to the right device\n",
    "SelfMdl.train() \n",
    "SelfMdl.to(device='cpu') \n",
    "FinalMdl.encoder = SelfMdl.get_encoder()\n",
    "FinalMdl.train()\n",
    "FinalMdl.to(device=device)\n",
    "\n",
    "# DEFINE LOSS\n",
    "def loss_fineTuning(yhat, ytrue):\n",
    "    ytrue = ytrue + 0.\n",
    "    yhat = torch.squeeze(yhat)\n",
    "    return F.binary_cross_entropy_with_logits(yhat, ytrue)\n",
    "\n",
    "# DEFINE EARLYSTOPPER\n",
    "earlystopFT = selfeeg.ssl.EarlyStopping(patience=10, min_delta=1e-03, record_best_weights=True)\n",
    "\n",
    "# DEFINE OPTIMIZER \n",
    "optimizerFT = torch.optim.Adam(FinalMdl.parameters(), lr=1e-3)\n",
    "schedulerFT = torch.optim.lr_scheduler.ExponentialLR(optimizerFT, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069787cc-1a7a-4698-b777-fdd5918c3c33",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Fine-tuning can be easily performed with the fine-tuning method.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>NOTE 1</b> \n",
    "    \n",
    "it is better to first pretrain only the new head, and then update all model's weights. However, EEGNet is small and this is a simple example, so we directly fine-tune all the network.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd036c7a-3de5-4898-a8b7-71869429f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loss=selfeeg.ssl.fine_tune(model                 = FinalMdl,\n",
    "                                      train_dataloader      = trainloaderFT,\n",
    "                                      epochs                = 10,\n",
    "                                      optimizer             = optimizerFT,\n",
    "                                      loss_func             = loss_fineTuning, \n",
    "                                      lr_scheduler          = schedulerFT,\n",
    "                                      EarlyStopper          = earlystopFT,\n",
    "                                      validation_dataloader = valloaderFT,\n",
    "                                      verbose               = True,\n",
    "                                      device                = device,\n",
    "                                      return_loss_info      = True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c66d5a-e56b-4bc3-9bee-0943880ed454",
   "metadata": {},
   "source": [
    "## Evaluate fine-tuned model\n",
    "\n",
    "Now you can evaluate your model in whatever method you prefer. Here is a simple example with the classification report from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b9201-f10d-460d-8722-50984f66b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nb_classes=2\n",
    "FinalMdl.eval()\n",
    "ytrue=torch.zeros(len(testloaderFT.dataset))\n",
    "ypred=torch.zeros_like(ytrue)\n",
    "cnt=0\n",
    "for i, (X, Y) in enumerate(testloaderFT):\n",
    "    X=X.to(device=device)\n",
    "    ytrue[cnt:cnt+X.shape[0]]= Y \n",
    "    with torch.no_grad():\n",
    "        yhat = torch.sigmoid(FinalMdl(X)).to(device='cpu')\n",
    "        ypred[cnt:cnt+X.shape[0]] = torch.squeeze(yhat) \n",
    "    cnt += X.shape[0]\n",
    "\n",
    "print('Results of trivial Example\\n')\n",
    "print(classification_report(ytrue,ypred>0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
