{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88873f8-d613-4fd1-8415-a9681f5b1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.getcwd().split('/test')[0])\n",
    "import itertools\n",
    "import platform\n",
    "\n",
    "# IMPORT CLASSICAL PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORT TORCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# IMPORT CUSTOM SELF-SUPERVISED LEARNING FOR EEG LIBRARY\n",
    "from selfeeg import augmentation as aug\n",
    "from selfeeg import dataloading as dl\n",
    "from selfeeg import models as zoo\n",
    "from selfeeg import ssl\n",
    "from selfeeg import losses\n",
    "from selfeeg import utils\n",
    "\n",
    "def create_dataset(folder_name='Simulated_EEG',\n",
    "                   Sample_range= [512, 1025],\n",
    "                   Chans = 16,\n",
    "                   return_labels = True,\n",
    "                   seed=1234):\n",
    "    N=1000\n",
    "    if not(os.path.isdir(folder_name)):\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    np.random.seed(seed=seed)\n",
    "    classes = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        Sample = np.random.randint(Sample_range[0],Sample_range[1])\n",
    "        y = np.random.choice([0,1], p=[0.8,0.2])\n",
    "        classes[i] = y\n",
    "        x = 600\n",
    "        while (np.max(x)>550 or np.min(x)<-550):\n",
    "            if y == 1:\n",
    "                stderr = np.sqrt(122.35423)\n",
    "                F1 = np.random.normal(0.932649, 0.040448)\n",
    "                F0 = np.random.normal(2.1159355, 2.3523977)\n",
    "            else:\n",
    "                stderr = np.sqrt(454.232666)\n",
    "                F1 = np.random.normal(0.9619603, 0.0301687)\n",
    "                F0 = np.random.normal(-0.1810323, 3.4712047)\n",
    "            x = np.zeros((Chans,Sample))\n",
    "            x[:,0] = np.random.normal( 0, stderr, Chans )  \n",
    "            for k in range(1,Sample):\n",
    "                x[:,k] = F0+ F1*x[:,k-1] + np.random.normal( 0, stderr, Chans )\n",
    "                \n",
    "        sample = {'data': x, 'label': y}\n",
    "        A, B, C = (int(i//200)+1), (int( (i - 200*int(i//200)))//5+1), (i%5+1)\n",
    "        file_name = 'Simulated_EEG/' + str(A) + '_' + str(B) + '_' + str(C) + '_1.pickle'\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(sample, f)\n",
    "    if return_labels:\n",
    "        return classes\n",
    "\n",
    "def loadEEG(path, return_label=False):\n",
    "    with open(path, 'rb') as handle:\n",
    "        EEG = pickle.load(handle)\n",
    "    x = EEG['data']\n",
    "    y = EEG['label']\n",
    "    if return_label:\n",
    "        return x, y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def transformEEG(EEG, value=64):\n",
    "    EEG = EEG[:,:-value]\n",
    "    return EEG\n",
    "\n",
    "def makeGrid(pars_dict):  \n",
    "    keys=pars_dict.keys()\n",
    "    combinations=itertools.product(*pars_dict.values())\n",
    "    ds=[dict(zip(keys,cc)) for cc in combinations]\n",
    "    return ds\n",
    "\n",
    "device  = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fca869b-a58b-451b-8e13-772392f3c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation_test.ipynb\n",
      "augmentation_test.py\n",
      "dataload_test.ipynb\n",
      "dataload_test.py\n",
      "loss_test.ipynb\n",
      "loss_test.py\n",
      "models_test.ipynb\n",
      "models_test.py\n",
      "__pycache__\n",
      "run_all_test.py\n",
      "selfeegdev\n",
      "Simulated_EEG\n",
      "ssl_test.ipynb\n",
      "ssl_test.py\n",
      "tmpsave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea17614-cf82-4356-9b7d-a0fea37131ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "TESTING SSL MODULE\n",
      "Found cuda device: testing ssl module on it\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------')\n",
    "print('TESTING SSL MODULE')\n",
    "if device.type != 'cpu':\n",
    "    print('Found cuda device: testing ssl module on it')\n",
    "else:\n",
    "    print('Didn\\'t found cuda device: testing ssl module on cpu')\n",
    "print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f1c6ed-ee74-474c-88c4-af763e025292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining dataloaders, augmenter and model\n"
     ]
    }
   ],
   "source": [
    "# DEFINE FILE PATH, SAMPLING RATE, WINDOW LENGTH, OVERLAP PERCENTAGE, WORKERS AND BATCH SIZE\n",
    "print('Defining dataloaders, augmenter and model')\n",
    "eegpath = 'Simulated_EEG'\n",
    "freq = 128\n",
    "window = 2\n",
    "overlap = 0.1\n",
    "workers = 4\n",
    "batchsize = 16\n",
    "Chan = 16\n",
    "\n",
    "classes = create_dataset()\n",
    "\n",
    "# CALCULATE DATASET LENGTH\n",
    "EEGlen = dl.GetEEGPartitionNumber(eegpath, freq, window, overlap, file_format='*.pickle', \n",
    "                                  load_function=loadEEG)\n",
    "\n",
    "# SPLIT DATASET\n",
    "EEGsplit= dl.GetEEGSplitTable(partition_table=EEGlen, val_ratio= 0.1, stratified=True, labels=classes,\n",
    "                              test_data_id=[5], split_tolerance=0.001, perseverance=5000)\n",
    "\n",
    "# DEFINE TRAINING DATALOADER\n",
    "trainset = dl.EEGDataset(EEGlen, EEGsplit, [freq, window, overlap], load_function=loadEEG)\n",
    "trainsampler = dl.EEGsampler(trainset, batchsize, workers)\n",
    "trainloader = DataLoader(dataset = trainset, batch_size= batchsize, sampler=trainsampler, num_workers=workers)\n",
    "\n",
    "# DEFINE VALIDATION DATALOADER\n",
    "valset = dl.EEGDataset(EEGlen, EEGsplit, [freq, window, overlap], 'validation', load_function=loadEEG)\n",
    "valloader = DataLoader(dataset = valset, batch_size= batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc63a8d-7bc2-4758-a7d2-488033a76fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE AUGMENTER\n",
    "# First block: noise addition\n",
    "AUG_band = aug.DynamicSingleAug(aug.add_band_noise, \n",
    "                                 discrete_arg={'bandwidth': [\"delta\", \"theta\", \"alpha\", \"beta\", (30,49) ], \n",
    "                                               'samplerate': freq,'noise_range': 0.5}\n",
    "                               )\n",
    "AUG_mask = aug.DynamicSingleAug(aug.masking, discrete_arg = {'mask_number': [1,2,3,4], 'masked_ratio': 0.25})\n",
    "Block1 = aug.RandomAug( AUG_band, AUG_mask, p=[0.7, 0.3])\n",
    "\n",
    "# second block: rescale\n",
    "Block2 = lambda x: utils.scale_range_soft_clip(x, 500, 1.5, 'uV', True)\n",
    "\n",
    "# FINAL AUGMENTER: SEQUENCE OF THE THREE RANDOM LISTS\n",
    "Augmenter = aug.SequentialAug(Block1, Block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a214b2-5765-434b-8aba-3f8ba417ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSL model\n",
    "emb_size= 16*((freq*window)//int(4*8))\n",
    "head_size=[ emb_size, 128, 64]\n",
    "predictor_size= [64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae83c16-3e54-4c8e-bdf2-7689a2a5a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimCLR (5 epochs, verbose True)...\n",
      "epoch [1/5]\n",
      "  0%|               | 0/165 [? Batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delpup/miniconda3/envs/selfdlp/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   val 21/21: 100%|███████████████| 165/165 [26.83 Batch/s, train_loss=4.46197, val_loss=4.23242]  \n",
      "epoch [2/5]\n",
      "   val 21/21: 100%|███████████████| 165/165 [39.68 Batch/s, train_loss=3.97520, val_loss=4.13144]  \n",
      "epoch [3/5]\n",
      "   val 21/21: 100%|███████████████| 165/165 [41.15 Batch/s, train_loss=3.90088, val_loss=3.94393]  \n",
      "epoch [4/5]\n",
      "   val 21/21: 100%|███████████████| 165/165 [44.38 Batch/s, train_loss=3.85470, val_loss=4.04300]  \n",
      "epoch [5/5]\n",
      "   val 21/21: 100%|███████████████| 165/165 [40.89 Batch/s, train_loss=3.80086, val_loss=4.17162]  \n",
      "no improvement after 2 epochs. Training stopped.\n",
      "   SimCLR OK\n"
     ]
    }
   ],
   "source": [
    "print('Testing SimCLR (5 epochs, verbose True)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.SimCLR(encoder=NNencoder, projection_head=head_size).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.SimCLR_loss\n",
    "loss_arg={'temperature': 0.5}\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=2, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-3)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss, loss_args= loss_arg,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=True, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   SimCLR OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d251744-e461-4559-84bc-2c76a17bfe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MoCo v2 (5 epochs, verbose False)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   MoCo v2 OK\n"
     ]
    }
   ],
   "source": [
    "#Moco\n",
    "print('Testing MoCo v2 (5 epochs, verbose False)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.MoCo(encoder=NNencoder, projection_head=head_size, bank_size=1024, m=0.9995).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.Moco_loss\n",
    "loss_arg={'temperature': 0.5}\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=6, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-4)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss, loss_args= loss_arg,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   MoCo v2 OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e706ae6-3631-4422-8613-1111ad149d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MoCo v3 (5 epochs, verbose False)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   MoCo v3 OK\n"
     ]
    }
   ],
   "source": [
    "#Moco\n",
    "print('Testing MoCo v3 (5 epochs, verbose False)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.MoCo(encoder=NNencoder, projection_head=head_size, predictor=predictor_size, m=0.9995).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.Moco_loss\n",
    "loss_arg={'temperature': 0.5}\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=6, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-4)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss, loss_args= loss_arg,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   MoCo v3 OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac69b15-52a4-474f-8a85-6c70eba65145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BYOL (5 epochs, verbose False)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   BYOL OK\n"
     ]
    }
   ],
   "source": [
    "#Moco\n",
    "print('Testing BYOL (5 epochs, verbose False)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.BYOL(encoder=NNencoder, projection_head=head_size, predictor=predictor_size, m=0.9995).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.BYOL_loss\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=6, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-4)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   BYOL OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862a8472-2df8-43fa-be59-40a9585a43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SimSiam (5 epochs, verbose False)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   SimSiam OK\n"
     ]
    }
   ],
   "source": [
    "#Moco\n",
    "print('Testing SimSiam (5 epochs, verbose False)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.SimSiam(encoder=NNencoder, projection_head=head_size, predictor=predictor_size).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.SimSiam_loss\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=6, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-4)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   SimSiam OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292ace65-3061-4955-81d8-f2adc76b55c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing VICReg (5 epochs, verbose True)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   VICReg OK\n"
     ]
    }
   ],
   "source": [
    "print('Testing VICReg (5 epochs, verbose True)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.VICReg(encoder=NNencoder, projection_head=head_size).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.VICReg_loss\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=2, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-3)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   VICReg OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95be855c-5dab-4686-9520-b0d62d478fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Barlow_Twins (5 epochs, verbose True)...\n",
      "epoch [1/5]\n",
      "epoch [2/5]\n",
      "epoch [3/5]\n",
      "epoch [4/5]\n",
      "epoch [5/5]\n",
      "   Barlow_Twins OK\n"
     ]
    }
   ],
   "source": [
    "print('Testing Barlow_Twins (5 epochs, verbose True)...')\n",
    "\n",
    "NNencoder= zoo.EEGNetEncoder(Chans=Chan, kernLength=65)\n",
    "SelfMdl = ssl.Barlow_Twins(encoder=NNencoder, projection_head=head_size).to(device=device)\n",
    "\n",
    "# loss (fit method has a default loss based on the SSL algorithm\n",
    "loss=losses.Barlow_loss\n",
    "\n",
    "# earlystopper\n",
    "earlystop = ssl.EarlyStopping(patience=2, min_delta=1e-05, record_best_weights=True)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(SelfMdl.parameters(), lr=1e-3)\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "loss_info = SelfMdl.fit(train_dataloader = trainloader, augmenter=Augmenter, epochs=5,\n",
    "                        optimizer=optimizer, loss_func= loss,\n",
    "                        lr_scheduler= scheduler, EarlyStopper=earlystop,\n",
    "                        validation_dataloader=valloader,\n",
    "                        verbose=False, device= device, return_loss_info=True\n",
    "                       )\n",
    "print('   Barlow_Twins OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15edafd1-8682-47f6-8d99-8d894f02d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing fine-tuning phase (10 epochs, verbose True)...\n",
      "epoch [1/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.64 Batch/s, train_loss=0.90282, val_loss=0.82893]  \n",
      "epoch [2/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.97 Batch/s, train_loss=0.86551, val_loss=0.79081]  \n",
      "epoch [3/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [10.58 Batch/s, train_loss=0.85415, val_loss=0.78070]  \n",
      "epoch [4/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [12.11 Batch/s, train_loss=0.83354, val_loss=0.76439]  \n",
      "epoch [5/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.07 Batch/s, train_loss=0.82394, val_loss=0.74826]  \n",
      "epoch [6/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.78 Batch/s, train_loss=0.80720, val_loss=0.73790]  \n",
      "epoch [7/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [10.34 Batch/s, train_loss=0.80469, val_loss=0.72855]  \n",
      "epoch [8/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.25 Batch/s, train_loss=0.80758, val_loss=0.72672]  \n",
      "epoch [9/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [11.87 Batch/s, train_loss=0.78930, val_loss=0.70731]  \n",
      "epoch [10/10]\n",
      "   val 4/4: 100%|███████████████| 33/33 [12.30 Batch/s, train_loss=0.78811, val_loss=0.69767]  \n",
      "   fine-tuning OK\n"
     ]
    }
   ],
   "source": [
    "print('testing fine-tuning phase (10 epochs, verbose True)...')\n",
    "\n",
    "# Extract only the samples for fine-tuning\n",
    "filesFT= EEGsplit.loc[EEGsplit['split_set']==2, 'file_name'].values\n",
    "EEGlenFT= EEGlen.loc[EEGlen['file_name'].isin(filesFT)].reset_index().drop(columns=['index'])\n",
    "labels = classes[ EEGsplit[EEGsplit['split_set']==2].index.tolist()]\n",
    "\n",
    "# split the fine-tuning data in train-test-validation\n",
    "EEGsplitFT = dl.GetEEGSplitTable(partition_table=EEGlenFT, test_ratio = 0.2, val_ratio= 0.1, val_ratio_on_all_data=False,\n",
    "                                 stratified=True, labels=labels, split_tolerance=0.001, perseverance=10000)\n",
    "\n",
    "# TRAINING DATALOADER\n",
    "trainsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'train', \n",
    "                           supervised=True, label_on_load=True, \n",
    "                           load_function=loadEEG, optional_load_fun_args=[True])\n",
    "trainsamplerFT = dl.EEGsampler(trainsetFT, batchsize, workers)\n",
    "trainloaderFT = DataLoader(dataset = trainsetFT, batch_size= batchsize, sampler=trainsamplerFT, num_workers=workers)\n",
    "\n",
    "# VALIDATION DATALOADER\n",
    "valsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'validation', \n",
    "                         supervised=True, label_on_load=True, \n",
    "                         load_function=loadEEG, optional_load_fun_args=[True])\n",
    "valloaderFT = DataLoader(dataset = valsetFT, batch_size= batchsize, num_workers=workers, shuffle=False)\n",
    "\n",
    "#TEST DATALOADER\n",
    "testsetFT = dl.EEGDataset(EEGlenFT, EEGsplitFT, [freq, window, overlap], 'test', \n",
    "                          supervised=True, label_on_load=True, \n",
    "                          load_function=loadEEG, optional_load_fun_args=[True])\n",
    "testloaderFT = DataLoader(dataset = testsetFT, batch_size= batchsize, shuffle=False)\n",
    "\n",
    "FinalMdl = zoo.EEGNet(nb_classes = 2, Chans = Chan, Samples = int(freq*window), kernLength = 65)\n",
    "\n",
    "# Transfer the pretrained backbone and move the final model to the right device\n",
    "SelfMdl.train() \n",
    "SelfMdl.to(device='cpu') \n",
    "FinalMdl.encoder = SelfMdl.get_encoder()\n",
    "FinalMdl.train()\n",
    "FinalMdl.to(device=device)\n",
    "\n",
    "# DEFINE LOSS\n",
    "def loss_fineTuning(yhat, ytrue):\n",
    "    ytrue = ytrue + 0.\n",
    "    yhat = torch.squeeze(yhat)\n",
    "    return F.binary_cross_entropy_with_logits(yhat, ytrue, pos_weight = torch.tensor([2.5]).to(device=device) )\n",
    "\n",
    "# DEFINE EARLYSTOPPER\n",
    "earlystopFT = ssl.EarlyStopping(patience=10, min_delta=1e-03, record_best_weights=True)\n",
    "\n",
    "# DEFINE OPTIMIZER \n",
    "optimizerFT = torch.optim.Adam(FinalMdl.parameters(), lr=1e-3)\n",
    "schedulerFT = torch.optim.lr_scheduler.ExponentialLR(optimizerFT, gamma=0.97)\n",
    "\n",
    "finetuning_loss=ssl.fine_tune(model                 = FinalMdl,\n",
    "                              train_dataloader      = trainloaderFT,\n",
    "                              epochs                = 10,\n",
    "                              optimizer             = optimizerFT,\n",
    "                              loss_func             = loss_fineTuning, \n",
    "                              lr_scheduler          = schedulerFT,\n",
    "                              EarlyStopper          = earlystopFT,\n",
    "                              validation_dataloader = valloaderFT,\n",
    "                              verbose               = True,\n",
    "                              device                = device,\n",
    "                              return_loss_info      = True\n",
    "                             )\n",
    "\n",
    "print('   fine-tuning OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95a9ef-4814-4164-be3e-180cac21a4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330cc21-c923-4cb5-acdd-a8c3fd9da297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd0ebe-6a13-484c-bfb8-df7cac43f9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
