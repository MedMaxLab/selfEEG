<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>selfeeg.losses package &mdash; SelfEEG 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="selfeeg.models package" href="selfeeg.models.html" />
    <link rel="prev" title="selfeeg.dataloading package" href="selfeeg.dataloading.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SelfEEG
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">selfeeg</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="selfeeg.html">selfeeg package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="selfeeg.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="selfeeg.augmentation.html">selfeeg.augmentation package</a></li>
<li class="toctree-l4"><a class="reference internal" href="selfeeg.dataloading.html">selfeeg.dataloading package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">selfeeg.losses package</a></li>
<li class="toctree-l4"><a class="reference internal" href="selfeeg.models.html">selfeeg.models package</a></li>
<li class="toctree-l4"><a class="reference internal" href="selfeeg.ssl.html">selfeeg.ssl package</a></li>
<li class="toctree-l4"><a class="reference internal" href="selfeeg.utils.html">selfeeg.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="selfeeg.html#module-selfeeg">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SelfEEG</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">selfeeg</a></li>
          <li class="breadcrumb-item"><a href="selfeeg.html">selfeeg package</a></li>
      <li class="breadcrumb-item active">selfeeg.losses package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/selfeeg.losses.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="selfeeg-losses-package">
<h1>selfeeg.losses package<a class="headerlink" href="#selfeeg-losses-package" title="Permalink to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-selfeeg.losses.losses">
<span id="selfeeg-losses-losses-module"></span><h2>selfeeg.losses.losses module<a class="headerlink" href="#module-selfeeg.losses.losses" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.BYOL_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">BYOL_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projections_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#BYOL_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.BYOL_loss" title="Permalink to this definition"></a></dt>
<dd><p>Simple pytorch implementation of the BYOL loss function.
It’s pretty similar to SimSiam loss</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.Barlow_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">Barlow_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_coeff</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.005</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#Barlow_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.Barlow_loss" title="Permalink to this definition"></a></dt>
<dd><p>Pytorch implementation of the Baarlow Twins loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z1</strong> (<em>torch.tensor</em>) – 2-D tensor with projections of one augmented version of the batch</p></li>
<li><p><strong>z2</strong> (<em>torch.tensor</em>) – 2-D projections of the other augmented version of the batch. Can be none if z1 and z2 are cat
together. In this case internal split is done</p></li>
<li><p><strong>lambda_coeff</strong> (<em>float</em><em>, </em><em>optional</em>) – off diagonal scaling factor described in the paper
Default: 5e-3</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.Moco_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">Moco_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">queue</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projections_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.15</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#Moco_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.Moco_loss" title="Permalink to this definition"></a></dt>
<dd><p>Simple implementation of Moco’s loss. It’s the InfoNCE loss with dot product as similarity and
memory bank as negative samples. If no queue related to the memory bank is given, Moco v3 loss
calculation are performed</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>q</strong> (<em>torch.Tensor</em>) – 2-D (NxC) Tensor with the queries, i.e. one augmented batch predictor or projection_head output.
N = batch size, C = number of features</p></li>
<li><p><strong>k</strong> (<em>torch.Tensor</em>) – 2-D (NxC) Tensor with the keys, i.e. one augmented batch projection_head output which will be
added to the memory bank.
N = batch size
C = number of features</p></li>
<li><p><strong>queue</strong> (<em>torch.Tensor</em>) – 2-D (CxK) Tensor with the memory bank, i.e. a collection of previous augmented batch
projection_head outputs which acts as negative samples.
C = number of features
K = memory bank size</p></li>
<li><p><strong>projections_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to normalize the projections or not.
Default= True</p></li>
<li><p><strong>temperature</strong> (<em>float</em><em>, </em><em>optional</em>) – temperature coefficient of the NTX_ent loss. (See references to check loss formula)
Default: 0.15</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>To check how NTXent work and how it is used to compute the loss read:
Chen et al. A Simple Framework for Contrastive Learning of Visual Representations. (2020).
<a class="reference external" href="https://doi.org/10.48550/arXiv.2002.05709">https://doi.org/10.48550/arXiv.2002.05709</a></p>
<p>To check the original tensorflow implementation visit the following repository:
<a class="reference external" href="https://github.com/google-research/simclr">https://github.com/google-research/simclr</a> (look at the function add_contrastive_loss
in objective.py)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.SimCLR_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">SimCLR_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">projections</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projections_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.15</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#SimCLR_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.SimCLR_loss" title="Permalink to this definition"></a></dt>
<dd><p>SimCLR compute the normalized temperature-scaled cross entropy loss, which is used in many
contrastive learning algorithm. It is basically a simple implementation of the InfoNCE_loss
provided in the official simCLR repository using only torch functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>projections</strong> (<em>torch.Tensor</em>) – 2-D Tensor where projections[0:N/2] are the projections of one batch augmented version
and projections[N/2:] are the projections of the other batch augmented version</p></li>
<li><p><strong>projections_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to normalize the projections or not
Default= True</p></li>
<li><p><strong>temperature</strong> (<em>float</em><em>, </em><em>optional</em>) – temperature coefficient of the NTX_ent loss. (See references to check loss formula)
Default: 0.15</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>To check how NTXent work and how it is used to compute the loss read:
Chen et al. A Simple Framework for Contrastive Learning of Visual Representations. (2020).
<a class="reference external" href="https://doi.org/10.48550/arXiv.2002.05709">https://doi.org/10.48550/arXiv.2002.05709</a></p>
<p>To check the original tensorflow implementation visit the following repository:
<a class="reference external" href="https://github.com/google-research/simclr">https://github.com/google-research/simclr</a> (look at the function add_contrastive_loss
in objective.py)</p>
<p>NOTE:
looking at some implementations (e.g. the one in lightlyAI), the returned loss seems to be double.
However the function add_contrastive_loss in the original repo return the same value as this
implementation, so we preferred to keep it the same.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.SimSiam_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">SimSiam_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projections_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#SimSiam_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.SimSiam_loss" title="Permalink to this definition"></a></dt>
<dd><p>Simple implementation of the SimSiam loss with the possibility to not normalize tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p1</strong> (<em>torch.Tensor</em>) – 2-D Tensor with one augmented batch predictor output</p></li>
<li><p><strong>z1</strong> (<em>torch.Tensor</em>) – 2-D Tensor with one augmented batch projection output</p></li>
<li><p><strong>p2</strong> (<em>torch.Tensor</em>) – same as p1 but with the other augmented batch</p></li>
<li><p><strong>z2</strong> (<em>torch.Tensor</em>) – same as z1 with the other augmented batch</p></li>
<li><p><strong>projections_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to normalize the projections or not
Default= True</p></li>
<li><p><strong>repo</strong> (<em>Original github</em>) – </p></li>
<li><p><strong>https</strong> (<em>//arxiv.org/abs/2011.10566</em>) – </p></li>
<li><p><strong>paper</strong> (<em>Original</em>) – </p></li>
<li><p><strong>Learning.</strong> (<em>Chen &amp; He. Exploring Simple Siamese Representation</em>) – </p></li>
<li><p><strong>https</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="selfeeg.losses.losses.VICReg_loss">
<span class="sig-prename descclassname"><span class="pre">selfeeg.losses.losses.</span></span><span class="sig-name descname"><span class="pre">VICReg_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">z2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lambda</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Mu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Nu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/selfeeg/losses/losses.html#VICReg_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#selfeeg.losses.losses.VICReg_loss" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-selfeeg.losses">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-selfeeg.losses" title="Permalink to this heading"></a></h2>
<p>losses import</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="selfeeg.dataloading.html" class="btn btn-neutral float-left" title="selfeeg.dataloading package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="selfeeg.models.html" class="btn btn-neutral float-right" title="selfeeg.models package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, MedMax Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>